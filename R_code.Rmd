---
title: "Mood"
author: "Arda Ergin"
date: "2024-04-02"
output: html_document
---

# Setup
```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
library(patchwork)
library(scales)
library(lubridate)
# Analysis
library(lme4)
library(Matrix)
```

```{r}
data_raw <- read.csv("data.csv")
```


How many variables and how many participants?
```{r}
unique(data_raw$variable)
unique(data_raw$id)
```

Some Quick Fixes:
```{r}
##### ID #####
# Getting a better ID column:
data_0 <- data_raw %>%
  mutate(ID = as.numeric(sapply(
    strsplit(id, split = '\\.'), function(x) x[2])))
# Factorizing the ID variable
data_0$ID <- factor(data_0$ID)

##### "X" #####
# Changing the name for the "X" variable
colnames(data_0)[1] <- "obs_number"


# Getting rid of the id variable
data_1 <- data_0[,c("obs_number", "time", "ID", "variable", "value")]
```

fixing time
```{r}
# Checking if there is any NAs in the `time` variable
any(is.na(data_1$time))

# Transforming the variable into an time variable:
data_1 <- data_1 %>% mutate(
  date_time = as.POSIXct(
    as.character(time), 
    format="%Y-%m-%d %H:%M:%OS"))
data_2 <- subset(data_1, select = -time)

# Quick Summary
summary(data_2$date_time)
```

Long to Wide Transformation:
```{r}
wide_data <- tidyr::pivot_wider(
  data_1, 
  names_from = variable, 
  values_from = value)

data <- as.data.frame(wide_data)
```

Looking at Just one Individual
```{r}
data_id_1 <- data %>% filter(ID == 1)
```





# Investigating Variables
## (ALL) Checking Range
```{r}
for(i in 1:ncol(data)){
  cat("\n=========\n")
  cat(colnames(data)[i])
  cat("\n=========\n")
  print(summary(data[,i]))
}
```

Based on these, cleaning the necessary data:
```{r}
# Taking a look at the problematic data
problematic <- data %>% filter(appCat.builtin < 0)
problematic

# Filtering these 3 responses 
data_cleaner <- data %>% filter(appCat.builtin >= 0 | is.na(appCat.builtin))
data <- data_cleaner
```


## Checking for Duplicates
```{r}
# Identifying duplicate rows
duplicates <- duplicated(data)

# View duplicate rows
data[duplicates, ]
```


## Mood
```{r}
# Quick Summary
summary(wide_data$mood)
table(wide_data$mood)

# Histogram
data %>% ggplot(aes(x = mood)) + 
  geom_histogram(bins = 10, color = "black", fill = "firebrick") +
  theme_classic(base_family = "Times") + 
  labs(title = "Distribution of Mood Observations", 
       x = "Mood", 
       y = "Frequency")
```

```{r}
mood_summary <- data %>%
  group_by(ID) %>%
  summarise(mean_mood = mean(mood, na.rm = TRUE),
            median_mood = median(mood, na.rm = TRUE),
            sd_mood = sd(mood, na.rm = TRUE),
            max_mood = max(mood, na.rm = TRUE),
            min_mood = min(mood, na.rm = TRUE))
mood_summary
```

Important the understand our DV, so good to summarize is for each participant.        
- Overall, there does not seem to be much of a difference between the individuals in terms of their mean and median.
- On the other hand, mood fluctuations are not the same for all individuals, and there might be individuals who experience more fluctuations.

```{r}
for (participant in unique(data$ID)) {
  moods <- data %>%
    filter(!is.na(mood))
  
  mood <- moods %>% filter(ID == participant)
  
  p <- mood %>% ggplot(
    aes(x = date_time, 
        y = mood)) +
    geom_line(color = colors()[sample(8:length(colors()),1)]) + 
    scale_y_continuous(limits = c(1, 10)) +
    theme_classic(base_family = "Times") + 
    theme(legend.position = "none") +
    labs(title = paste(
      "Mood Over Time for Participant Number", 
      participant), 
         x = "Time", 
         y = "Mood")
  
  print(p)
}
```

Participant number 7 have too much fluctuations and can be considered an outlier among the other participants. It might possibly be a good idea to exclude them. Maybe also participant number 33.

```{r}
# Creating a new variable in our "mood_summary" 
# Putting the ID to the column if the participant is an outlier 
# FROM: https://www.r-bloggers.com/2022/08/how-to-label-outliers-in-boxplots-in-ggplot2/
find_outlier <- function(x) {
  return(x < quantile(x, .25) - 1.5*IQR(x) | x > quantile(x, .75) + 1.5*IQR(x))
}

mood_summary <- mood_summary %>%
  mutate(outlier = ifelse(find_outlier(sd_mood), ID, NA))

mood_summary %>% ggplot(aes(x = "", y = sd_mood)) +
  geom_boxplot(color = "firebrick") +
  theme_classic() +
  labs(title = "Boxplot of Standard Deviation of Mood",
       y = "Standard Deviation of Mood",
       x = "") + 
  geom_text(aes(label=outlier), na.rm=TRUE, hjust=-1)
```

Although, it needs to be noted that individuals who have depression will show these mood fluctuations. If we assume that this sample is a representative sample, considering the $10-20\%$ prevalence, we should expect around $2-4$ individuals that are displaying such patterns. Hence, it is a question whether this should actually be considered as an "anomaly". 



## Arousal & Valence
```{r}
# Quick Summary: Arousal
summary(data$circumplex.arousal)
table(data$circumplex.arousal)

# Quick Summary: Valence
summary(data$circumplex.valence)
table(data$circumplex.valence)

# Histograms & Combining Them
hist_arousal <- data %>% ggplot(aes(x = circumplex.arousal)) + 
  geom_histogram(bins = 5, color = "black", fill = "deepskyblue2") +
  theme_classic(base_family = "Times") + 
  labs(title = "Distribution of Arousal", 
       x = "Arousal", 
       y = "Frequency")

hist_valence <- data %>% ggplot(aes(x = circumplex.valence)) + 
  geom_histogram(bins = 5, color = "black", fill = "purple2") +
  theme_classic(base_family = "Times") + 
  labs(title = "Distribution of Valence", 
       x = "Valence", 
       y = "Frequency")

# Doing layout for ggpplot2:
(hist_arousal | hist_valence) + 
  patchwork::plot_layout(ncol = 2)
```



## Time

### New Variables
```{r}
# Creating Variable: the Date (of Observation)
data <- data %>%
  mutate(date = as.Date(date_time))

# Creating Variable: the Time (of Observation)
data <- data %>%
  mutate(time = format(date_time, "%H:%M:%S"))

# Creating Variable: the Hour (of Observation)
data <- data %>%
  mutate(hour = format(date_time, "%H"))
data$hour <- as.numeric(data$hour)

# Creating Variable: the day of the week (of Observation)
data <- data %>%
  mutate(weekday = weekdays(date_time),
         weekday = factor(
           weekday, 
           levels = c("Monday", "Tuesday", 
                      "Wednesday", "Thursday", 
                      "Friday", "Saturday", 
                      "Sunday")))

# Creating Variable: the week of the year (of Observation)
data <- data %>%
  mutate(week_of_year = lubridate::week(date_time))
```


### Visual: Entire Time
```{r}
length(unique(data$date))
# Histogram
data %>% ggplot(aes(x = date)) + 
  geom_histogram(bins = 112, 
                 color = "black", 
                 fill = "purple2") +
  theme_classic(base_family = "Times") + 
  labs(title = "Distribution of Observations", 
       x = "Date-Time", 
       y = "Frequency") + scale_x_date(breaks = "1 week",date_labels = "%d-%m")
```

### Visual: Hour x Observ.
```{r}
data %>% ggplot(aes(x = hour)) + 
  geom_histogram(bins = 24, 
                 color = "black", 
                 fill = "purple2") + 
  theme_classic(base_family = "Times") + 
  labs(title = "Frequency of Observations Per Hour", 
       x = "Hour",
       y = "Frequency") + 
  scale_x_continuous(breaks = 0:23)
```

### Visual: Hour x Activity

```{r}
# Summarizing Per Weekday
hour_activity <- data %>%
  group_by(hour) %>%
  summarise(
    mean_act = mean(activity, na.rm = TRUE),
    sd_act = sd(activity, na.rm = TRUE),
    n = sum(!is.na(activity)),
    sem = sd_act / sqrt(n),
    ci_lower = mean_act - qnorm(0.975) * sem,
    ci_upper = mean_act + qnorm(0.975) * sem
  )

# Bar Plot
hour_activity %>%
  ggplot(aes(
    x = hour, 
    y = mean_act)) + 
  geom_col(color = "black", 
           fill = "skyblue1") +
  geom_errorbar(aes(ymin = ci_lower, 
                    ymax = ci_upper), 
                width = .2) + 
  theme_classic(base_family = "Times") +
  labs(
    title = "Mean Activity per Hour",
    x = "Hour",
    y = "Mean Activity"
  )
```


### Visual: Weekdays
```{r}
# Summarizing Per Weekday
weekday_summary <- data %>%
  group_by(weekday) %>%
  summarise(
    mean_mood = mean(mood, na.rm = TRUE),
    sd_mood = sd(mood, na.rm = TRUE),
    n = sum(!is.na(mood)),
    sem = sd_mood / sqrt(n),
    ci_lower = mean_mood - qnorm(0.975) * sem,
    ci_upper = mean_mood + qnorm(0.975) * sem
  )

# Bar Plot
weekday_summary %>%
  ggplot(aes(
    x = weekday, 
    y = mean_mood)) + 
  geom_col(color = "black", 
           fill = "skyblue1") +
  geom_errorbar(aes(ymin = ci_lower, 
                    ymax = ci_upper), 
                width = .2) +  
  geom_text(aes(
    label = paste("n =", n), 
    y = mean_mood + 0.02), 
    vjust = -5.5,
    family = "Times New Roman") + 
  theme_classic(base_family = "Times") +
  labs(
    title = "Mean Mood per Weekday",
    x = "Weekday",
    y = "Mean Mood"
  ) + 
  coord_cartesian(ylim = c(6.8,7.5))
```


### Visual: Week of Year
```{r}
# Summarizing Per Weekday
week_summary <- data %>%
  group_by(week_of_year) %>%
  summarise(
    mean_mood = mean(mood, na.rm = TRUE),
    sd_mood = sd(mood, na.rm = TRUE),
    n = sum(!is.na(mood)),
    sem = sd_mood / sqrt(n),
    ci_lower = mean_mood - qnorm(0.975) * sem,
    ci_upper = mean_mood + qnorm(0.975) * sem
  )

# Bar Plot
week_summary %>%
  ggplot(aes(
    x = week_of_year, 
    y = mean_mood)) + 
  geom_col(color = "black", 
           fill = "skyblue") +
  geom_errorbar(aes(ymin = ci_lower, 
                    ymax = ci_upper), 
                width = .2) +  
  geom_text(aes(
    label = n, 
    y = mean_mood + 0.02), 
    vjust = -10,
    family = "Times New Roman") + 
  theme_classic(base_family = "Times") +
  labs(
    title = "Mean Mood per Week of the Year",
    x = "Week of the Year",
    y = "Mean Mood"
  ) + 
  coord_cartesian(ylim = c(6,7.6))
  
```



### *** Filtering Time ***

```{r}
table(data$date)
# 2014-03-13 or 2014-03-20
# 2014-05-29 or 2014-05-05
```



```{r}
# A bit more conservative: 
data_filter_time <- data %>% filter(date > "2014-03-13" & date < "2014-05-29")
# > 4000
data_filter_time_2 <- data %>% filter(date > "2014-03-20" & date < "2014-05-05")
```


```{r}
data_filter_time_2 %>% ggplot(aes(x = date)) + 
  geom_histogram(bins = length(unique(data_filter_time_2$date)), 
                 color = "black", 
                 fill = "purple2") +
  theme_classic(base_family = "Times") + 
  labs(title = "Distribution of Observations over Time", 
       x = "Date-Time", 
       y = "Frequency") + 
  scale_x_date(
    breaks = seq(as.Date("2014-03-21"), 
                 as.Date("2014-05-04"), 
                 by = "1 day"), 
    date_labels = "%d-%m") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
data <- data_filter_time_2
```


# Fixing Days

## Observation Day
```{r}
# Adding a days_since_start column
data <- data %>% mutate(
  days_since_start = as.numeric(
    difftime(date, min(date), units = "days")))

# Check
unique(data$days_since_start)
```


## Taking a Look at Activity
```{r}
activity_count_per_hour <- data %>%
  filter(!is.na(activity)) %>%
  group_by(hour) %>%
  summarize(count = n())

# Bar Plot
activity_count_per_hour %>%
  ggplot(aes(
    x = hour, 
    y = count)) + 
  geom_col(color = "black", 
           fill = "orange") + coord_cartesian(ylim=c(700,900))
```


```{r}
activity_count_per_hour <- data %>%
  filter(activity == 0) %>%
  group_by(hour) %>%
  summarize(count = n())

# Bar Plot
activity_count_per_hour %>%
  ggplot(aes(
    x = hour, 
    y = count)) + 
  geom_col(color = "black", 
           fill = "orange")
```


```{r}
write.csv(data, "data_1.csv")
```



# Sleep
```{r}
data <- x
```

```{r}
# Sort data by date_time
data <- data %>% arrange(ID, date_time)
```

```{r}
# Potential Hours 
data <- data %>% mutate(
  after_midnight_activity = (hour >= 0 & hour <= 6),
  # Wake up Hour (first observation after the difference)
  potential_sleep_hour = (hour >= 20 | hour <= 11),
  # Wake up Hour (first observation after the difference)
  potential_wakeup_hour = (hour >= 5 & hour <= 12))
```

## Potential Sleep Gap
```{r}
# Column for the time difference between 
# the current observation and the last observation
data <- data %>% group_by(ID) %>% mutate(
  # For every observation, getting the difference between the previous
  time_diff = round(
    difftime(date_time, lag(date_time),
             units = "hours"), 3),
  # Gap based on both these variables
  possible_sleep_gap = (time_diff >= 5 & time_diff <= 15) & 
    (potential_wakeup_hour == TRUE)) %>% 
  ungroup()
```

## Inactivity
```{r}
# Inactivity
data <- data %>% mutate(
  is_inactive = dplyr::case_when(
    is.na(activity) ~ FALSE,
    activity == 0 ~ TRUE,
    TRUE ~ FALSE))

# Applying a run-length encoding to count consecutive inactive periods
data <- data %>% group_by(ID) %>% mutate(
    consecutive_inactive = with(rle(is_inactive), {
      # Only count lengths where is_inactive is TRUE:
      lengths_corrected <- lengths * values  
      # Repeat these lengths according to run lengths:
      rep(lengths_corrected, lengths)   
    })) %>% 
  ungroup()
```

## Fragmented Sleep
```{r}
########  1  #############
# last inactive hour
data <- data %>%
  mutate(
    # Check if current observation is inactive
    last_inactive_hour = if_else(is_inactive, hour, 
                                            NA_integer_)
  ) %>%
  group_by(ID) %>%
  # Fill NA values with the last known inactive hour, carrying it forward
  fill(last_inactive_hour, .direction = "down") %>%
  ungroup()

########  2  ##########
# Assuming data is already loaded and date_time is in POSIXct format
data <- data %>%
  mutate(
    # Record the datetime of the last inactive observation
    last_inactive_time = if_else(is_inactive, date_time, as.POSIXct(NA))
  ) %>%
  group_by(ID) %>%
  # Fill NA values with the last known inactive datetime, carrying it forward
  fill(last_inactive_time, .direction = "down") %>%
  ungroup() %>%
  mutate(
    # Calculate the time difference in hours between now and the last inactive time
    time_since_last_inactive = if_else(is.na(last_inactive_time),
                                       NA_real_,
                                       as.numeric(difftime(date_time, last_inactive_time, units = "hours")))
  )
```


## WORKING ON IT NOW
```{r}
# Determine if sleep occurred after midnight
data <- data %>% mutate(
    slept_after_midnight = hour(date_time) >= 0 & hour(date_time) <= 6 & sleep == 1)

```




## Sleep
```{r}
data <- data %>% group_by(ID)%>% mutate(
  sleep = case_when(
    consecutive_inactive >= 4 & 
      potential_sleep_hour ~ consecutive_inactive, 
    
    possible_sleep_gap & 
      potential_wakeup_hour ~ round(as.numeric(time_diff)),
    
    TRUE ~ 0
  )
) %>% ungroup()
```










# Aggregating

```{r}
# aggregating the data by date, for all participants
aggregated_data <- data %>%
  group_by(date, ID) %>%
  summarise(
    mood = mean(mood, na.rm = TRUE),
    arousal = mean(circumplex.arousal, na.rm = TRUE),
    valence = mean(circumplex.valence, na.rm = TRUE),
    activity = mean(activity, na.rm = TRUE),
    # screen???
    call = sum(call, na.rm = TRUE),
    sms = sum(sms, na.rm = TRUE),
    appCat.builtin = sum(appCat.builtin, na.rm = TRUE),
    appCat.communication = sum(appCat.communication, na.rm = TRUE),
    appCat.entertainment = sum(appCat.entertainment, na.rm = TRUE),
    appCat.finance = sum(appCat.finance, na.rm = TRUE),
    appCat.game = sum(appCat.game, na.rm = TRUE),
    appCat.office = sum(appCat.office, na.rm = TRUE),
    appCat.other = sum(appCat.other, na.rm = TRUE),
    appCat.social = sum(appCat.social, na.rm = TRUE),
    appCat.travel = sum(appCat.travel, na.rm = TRUE),
    appCat.unknown = sum(appCat.unknown, na.rm = TRUE),
    appCat.utilities = sum(appCat.utilities, na.rm = TRUE), 
    appCat.weather = sum(appCat.weather, na.rm = TRUE), 
    .groups = "drop")

# Standardizing
aggregated_data_2 <- aggregated_data %>%
  mutate_at(vars(arousal:appCat.weather), scale)
colnames(aggregated_data_2)

# Model
model <- lme4::lmer(
  mood ~ arousal + 
    valence + 
    activity + 
    call + 
    sms + 
    appCat.builtin + 
    appCat.communication + 
    appCat.entertainment + 
    appCat.finance + 
    appCat.game + 
    appCat.office + 
    appCat.other + 
    appCat.social + 
    appCat.travel + 
    appCat.unknown + 
    appCat.utilities + 
    appCat.weather + 
    (1 + time|ID), 
  data = aggregated_data)
summary(model)
```


```{r}
write.csv(aggregated_data, "data_aggregated.csv")
```




# Network Shit

```{r}
load("/Users/arda/Downloads/NatureMethodsPrimer_NetworkAnalysis-main/Psychopathology/data/clean_network.RData")
```


```{r}
data <- data %>% mutate(
  beep = case_when(
    hour == 9 & !is.na(mood) ~ 1,
    hour == 12 & !is.na(mood) ~ 2,
    hour == 15 & !is.na(mood) ~ 3,
    hour == 18 & !is.na(mood) ~ 4,
    hour == 21 & !is.na(mood) ~ 5,
    TRUE ~ 0
  )
)
a <- data %>% filter(ID == 1)
write.csv(a, "a.csv")

sum(data$possible_beep == 1)
sum(!is.na(data$mood))

# Generate additional times
additional_times <- c("09:00:01", "12:00:01", "15:00:01", "18:00:01", "21:00:01")
dates <- unique(as.Date(data$date_time))
participants <- unique(data$ID)

# Create a data frame of all combinations of dates, times, and participants
expanded_data <- expand.grid(
  date = dates, 
  time = additional_times, 
  ID = participants)

expanded_data$date_time <- as.POSIXct(paste(expanded_data$date, expanded_data$time))

# Select only relevant columns and sort
expanded_data <- expanded_data[, c("ID", "date_time")]

# Combine with the original data
combined_data <- rbind(data, expanded_data)

# Remove duplicate rows and sort by date_time
combined_data <- combined_data %>%
  arrange(ID, date_time) %>%
  distinct()

# Fill in NA for columns not present in expanded_data
combined_data$mood[is.na(combined_data$mood)] <- NA


```



```{r}
# Generate additional times and beeps
additional_times <- c(
  "09:00:01", 
  "12:00:01", 
  "15:00:01", 
  "18:00:01", 
  "21:00:01")
beep_identifiers <- c(1, 2, 3, 4, 5) 
dates <- unique(as.Date(data$date_time))
participants <- unique(data$ID)

# Map times to beep identifiers
time_to_beep <- setNames(beep_identifiers, additional_times)
# Create a data frame of all combinations of dates, times, and participants
expanded_data <- expand.grid(date = dates, time = additional_times, ID = participants)
expanded_data$date_time <- as.POSIXct(paste(expanded_data$date, expanded_data$time))
expanded_data$beep_number <- time_to_beep[as.character(expanded_data$time)]

# Initialize columns for expanded_data that are in data but not in expanded_data
additional_columns <- setdiff(names(data), names(expanded_data))
for (col in additional_columns) {
  expanded_data[[col]] <- NA
}

# Combine original and expanded data
data$beep_number <- NA
combined_data <- rbind(data, expanded_data)

# Remove duplicate rows and sort by date_time
combined_data <- combined_data %>%
  arrange(ID, date_time) %>%
  distinct()
```


```{r}
library(zoo)

# Make sure it is sorted by ID and date_time
combined_data <- combined_data %>%
  arrange(ID, date_time)

# Fill beep_number NA values using zoo::na.locf()
combined_data$beepo <- na.locf(combined_data$beep_number, na.rm = FALSE, fromLast = TRUE)


# Example aggregation: Calculate the mean mood for each beep interval for each participant
# You can change this to match the specific columns and summary statistics you need
aggregated_data <- combined_data %>%
  group_by(ID, beep_number) %>%
  summarize(mean_mood = mean(mood, na.rm = TRUE), .groups = 'drop')

aggregated_data <- combined_data %>%
  group_by(ID, date, beepo) %>%
  summarise(
    mood = mean(mood, na.rm = TRUE),
    arousal = mean(circumplex.arousal, na.rm = TRUE),
    valence = mean(circumplex.valence, na.rm = TRUE),
    activity = mean(activity, na.rm = TRUE),
    # screen???
    call = sum(call, na.rm = TRUE),
    sms = sum(sms, na.rm = TRUE),
    appCat.builtin = sum(appCat.builtin, na.rm = TRUE),
    appCat.communication = sum(appCat.communication, na.rm = TRUE),
    appCat.entertainment = sum(appCat.entertainment, na.rm = TRUE),
    appCat.finance = sum(appCat.finance, na.rm = TRUE),
    appCat.game = sum(appCat.game, na.rm = TRUE),
    appCat.office = sum(appCat.office, na.rm = TRUE),
    appCat.other = sum(appCat.other, na.rm = TRUE),
    appCat.social = sum(appCat.social, na.rm = TRUE),
    appCat.travel = sum(appCat.travel, na.rm = TRUE),
    appCat.unknown = sum(appCat.unknown, na.rm = TRUE),
    appCat.utilities = sum(appCat.utilities, na.rm = TRUE), 
    appCat.weather = sum(appCat.weather, na.rm = TRUE), 
    .groups = "drop")
```


```{r}
install.packages("imputeTS")

imputed <- imputeTS::na_kalman(aggregated_data)
```



```{r}

```




