---
title: "Mood"
author: "Arda Ergin"
date: "2024-04-02"
output: html_document
---

# Setup
```{r}
# General
library(dplyr)
library(tidyr)
library(ggplot2)
library(patchwork)
library(scales)
library(lubridate)
library(lme4)
library(Matrix)
# Time Series
library(zoo)
# Imputation for Time Series
library(imputeTS)
# Network Analysis
library(mlVAR)
library(igraph)

# Bayesian Multilevel
library(mHMMbayes)

# Multiple Imputations
library(mice)
library(micemd)
library(miceadds)
```

```{r}
fix_time <- function(data){
  data_to_write <- data
  data_to_write <- data_to_write %>% mutate(
    date_time = format(date_time, format="%Y-%m-%d %H:%M:%S"))
  data_to_write$date_time <- as.character(data_to_write$date_time)
  return(data_to_write)
}

# Function to calculate mean only if not all values are NA
safe_mean <- function(x) {
  if (all(is.na(x))) NA else mean(x, na.rm = TRUE)
}

# Function to calculate sum only if not all values are NA
safe_sum <- function(x) {
  if (all(is.na(x))) NA else sum(x, na.rm = TRUE)
}
```


```{r}
data_raw <- read.csv("data/data.csv")
```


How many variables and how many participants?
```{r}
unique(data_raw$variable)
unique(data_raw$id)
```

Some Quick Fixes:
```{r}
##### ID #####
# Getting a better ID column:
data_0 <- data_raw %>%
  mutate(ID = as.numeric(sapply(
    strsplit(id, split = '\\.'), function(x) x[2])))
# Factorizing the ID variable 
# (it causes some headaches, so I will not do this until data analysis)
### data_0$ID <- factor(data_0$ID) ###

##### "X" #####
# Changing the name for the "X" variable
colnames(data_0)[1] <- "obs_number"


# Getting rid of the id variable
data_1 <- data_0[,c("obs_number", "time", "ID", "variable", "value")]
```


fixing time:
```{r}
# Checking if there is any NAs in the `time` variable
any(is.na(data_1$time))

# Transforming the variable into an time variable:
data_1 <- data_1 %>% mutate(
  date_time = as.POSIXct(
    as.character(time), 
    format="%Y-%m-%d %H:%M:%OS"))
data_2 <- subset(data_1, select = -time)

# Quick Summary
summary(data_2$date_time)
max(data_2$date_time) - min(data_2$date_time)
```

Long to Wide Transformation:
```{r}
wide_data <- tidyr::pivot_wider(
  data_1, 
  names_from = variable, 
  values_from = value)

data <- as.data.frame(wide_data)
```

Looking at Just one Individual
```{r}
data_id_1 <- data %>% filter(ID == 1)
```




# Cleaning
## Checking Ranges
```{r}
for(i in 1:ncol(data)){
  cat("\n=========\n")
  cat(colnames(data)[i])
  cat("\n=========\n")
  print(summary(data[,i]))
}
```

Based on these, cleaning the necessary data:
```{r}
# Taking a look at the problematic data
problematic <- data %>% filter(
  appCat.builtin < 0 | appCat.entertainment < 0)
problematic

# Filtering these 3 responses 
data_cleaner <- data %>% filter(
  (appCat.builtin >= 0 | is.na(appCat.builtin)) & 
  (appCat.entertainment >= 0 | is.na(appCat.entertainment))
  )

data <- data_cleaner
```

## --------------------

## Checking for Duplicates
```{r}
# Identifying duplicate rows
duplicates <- duplicated(data)

# View duplicate rows
data[duplicates, ]
```

There are no duplicate rows in the dataset.

## EXPORT DATA_0
```{r}
write.csv(data, "data/data_0_cleaned_responses.csv")
```















# Investigating Variables

## Time

### New Variables
```{r}
# Creating Variable: the Date (of Observation)
data <- data %>%
  mutate(date = as.Date(date_time))

# Creating Variable: the Time (of Observation)
data <- data %>%
  mutate(time = format(date_time, "%H:%M:%S"))

# Creating Variable: the Hour (of Observation)
data <- data %>%
  mutate(hour = format(date_time, "%H"))
data$hour <- as.numeric(data$hour)
```

### Visual: Entire Time
```{r}
# Histogram
hist_time <- data %>% ggplot(aes(x = date)) + 
  geom_histogram(bins = length(unique(data$date)), 
                 color = "black", 
                 fill = "purple2") +
  theme_classic(base_family = "Times") + 
  labs(title = "Distribution of Observations (17-02-2014 — 09-06-2014)", 
       x = "Date-Time", 
       y = "Frequency") + 
  scale_x_date(
    breaks = seq(as.Date(min(data$date)), 
                 as.Date(max(data$date)), 
                 by = "1 week"), 
    date_labels = "%d-%m") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(hist_time)
```


### FILTER Time: Trimming

```{r}
table(data$date)
# 2014-03-13 or 2014-03-20
# 2014-05-29 or 2014-05-05
```

```{r}
for (participant_ID in unique(data$ID)){
  cat(paste("participant ID: ",participant_ID))
  cat("\n")
  dataset <- data %>% filter(ID == participant_ID)
  print(min(dataset$date))
  print(max(dataset$date))
  cat("\n")
}
```

**Filtering** (depreciated technically ahahahaha)
```{r}
# > 4000
data_filter_time <- data %>% filter(
  date > "2014-03-20" & date < "2014-05-05")

# A bit more conservative approach: 
# data_filter_time <- data %>% filter(date > "2014-03-13" & date < "2014-05-29")
```


```{r}
hist_filtered_time <- data_filter_time %>% ggplot(aes(x = date)) + 
  geom_histogram(bins = length(unique(data_filter_time$date)), 
                 color = "black", 
                 fill = "purple2") +
  theme_classic(base_family = "Times") + 
  labs(title = "Distribution of Observations (21-03-2014 — 04-05-2014)", 
       x = "Date-Time", 
       y = "Frequency") + 
  scale_x_date(
    breaks = seq(as.Date("2014-03-21"), 
                 as.Date("2014-05-04"), 
                 by = "1 week"), 
    date_labels = "%d-%m") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(hist_filtered_time)
```

```{r}
(hist_time | hist_filtered_time) + 
  patchwork::plot_layout(ncol = 2)
```

```{r}
# data <- data_filter_time
```


### FILTER time: NA Removal
I have identified these manually after aggregating and looking at every participant:
```{r}
clean_id_time <- function(data){
  data_id_cleaned <- data %>% dplyr::filter(
    (ID == 1 & 
       date > "2014-03-20" & 
       date < "2014-05-05") | 
    (ID == 2 & 
       date > "2014-03-15" & 
       date < "2014-04-15") | 
    (ID == 3 & 
       date > "2014-03-20" & 
       date < "2014-05-08") | 
    (ID == 5 & 
       date > "2014-03-14" & 
       date < "2014-05-05") | 
    (ID == 6 & 
       date > "2014-03-24" & 
       date < "2014-05-08") | 
    (ID == 7 & 
       date > "2014-03-18" & 
       date < "2014-05-03") | 
    (ID == 8 & 
       date > "2014-03-12" & 
       date < "2014-05-05") | 
    (ID == 9 & 
       date > "2014-03-21" & 
       date < "2014-04-27") | 
    (ID == 12 & 
       date > "2014-03-26" & 
       date < "2014-05-05") | 
    (ID == 13 & 
       date > "2014-03-13" & 
       date < "2014-05-02") | 
    (ID == 13 & 
       date > "2014-03-13" & 
       date < "2014-05-03") | 
    (ID == 14 & 
       date > "2014-03-20" & 
       date < "2014-05-05") | 
    (ID == 15 & 
       date > "2014-03-13" & 
       date < "2014-05-06") | 
    (ID == 16 & 
       date > "2014-03-13" & 
       date < "2014-05-04") | 
    (ID == 17 & 
       date > "2014-03-20" & 
       date < "2014-05-05") | 
    (ID == 19 & 
       date > "2014-03-20" & 
       date < "2014-05-04") | 
    (ID == 20 & 
       date > "2014-03-21" & 
       date < "2014-04-29") | 
    (ID == 23 & 
       date > "2014-03-21" & 
       date < "2014-05-04") | 
    (ID == 24 & 
       date > "2014-04-14" & 
       date < "2014-06-08") |
    (ID == 25 & 
       date > "2014-04-08" & 
       date < "2014-05-08") | 
    (ID == 26 & 
       date > "2014-04-12" & 
       date < "2014-05-29") | 
    (ID == 27 & 
       date > "2014-04-02" & 
       date < "2014-05-14") | 
    (ID == 28 & 
       date > "2014-03-31" & 
       date < "2014-05-09") | 
    (ID == 29 & 
       date > "2014-03-31" & 
       date < "2014-05-14") |
    (ID == 30 & 
       date > "2014-03-19" & 
       date < "2014-05-05") | 
    (ID == 31 & 
       date > "2014-04-01" & 
       date < "2014-05-06") | 
    (ID == 32 & 
       date > "2014-04-01" & 
       date < "2014-05-13") | 
    (ID == 33 & 
       date > "2014-04-15" & 
       date < "2014-05-31")
  )
  return(data_id_cleaned)
}
data_id_cleaned <- clean_id_time(data)
```

```{r}
hist_filtered_time <- data_id_cleaned %>% ggplot(aes(x = date)) + 
  geom_histogram(bins = length(unique(data_id_cleaned$date)), 
                 color = "black", 
                 fill = "purple2") +
  theme_classic(base_family = "Times") + 
  labs(title = "Distribution of Observations (21-03-2014 — 04-05-2014)", 
       x = "Date-Time", 
       y = "Frequency") + 
  scale_x_date(date_labels = "%d-%m",
               breaks = seq(
                 as.Date("2014-03-13"), 
                 as.Date("2014-06-07"), 
                 by = "1 week")) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(hist_filtered_time)
```


### --------------------
```{r}
data <- data_id_cleaned
```


### EXPORT DATA_1

```{r}
data_to_write <- fix_time(data)
write.csv(data_to_write, "data/data_1_cleaned_and_time_filtered.csv")
```


### Visual: Hour x Observ.
```{r}
data %>% ggplot(aes(x = hour)) + 
  geom_histogram(bins = 24, 
                 color = "black", 
                 fill = "purple2") + 
  theme_classic(base_family = "Times") + 
  labs(title = "Frequency of Observations Per Hour", 
       x = "Hour",
       y = "Frequency") + 
  scale_x_continuous(breaks = 0:23)
```

### Visual: Hour x Activity

```{r}
# Summarizing Per Weekday
hour_activity <- data %>%
  group_by(hour) %>%
  summarise(
    mean_act = mean(activity, na.rm = TRUE),
    sd_act = sd(activity, na.rm = TRUE),
    n = sum(!is.na(activity)),
    sem = sd_act / sqrt(n),
    ci_lower = mean_act - qnorm(0.975) * sem,
    ci_upper = mean_act + qnorm(0.975) * sem
  )

# Bar Plot
hour_activity %>%
  ggplot(aes(
    x = hour, 
    y = mean_act)) + 
  geom_col(color = "black", 
           fill = "skyblue1") +
  geom_errorbar(aes(ymin = ci_lower, 
                    ymax = ci_upper), 
                width = .2) + 
  theme_classic(base_family = "Times") +
  labs(
    title = "Mean Activity per Hour",
    x = "Hour",
    y = "Mean Activity"
  )
```


## Mood
```{r}
# Quick Summary
summary(wide_data$mood)
table(wide_data$mood)

# Histogram
hist_mood <- data %>% filter(!is.na(mood)) %>% 
  ggplot(aes(x = mood)) + 
  geom_histogram(bins = 10, color = "black", fill = "firebrick") +
  theme_classic(base_family = "Times") + 
  labs(title = "Distribution of Mood", 
       x = "Mood", 
       y = "Frequency")
print(hist_mood)
```

```{r}
mood_summary <- data %>%
  group_by(ID) %>%
  summarise(
    mean_mood = mean(mood, na.rm = TRUE),
    median_mood = median(mood, na.rm = TRUE),
    sd_mood = sd(mood, na.rm = TRUE),
    max_mood = max(mood, na.rm = TRUE),
    min_mood = min(mood, na.rm = TRUE))
mood_summary
```

Important the understand our DV, so good to summarize is for each participant.        
- Overall, there does not seem to be much of a difference between the individuals in terms of their mean and median.
- On the other hand, mood fluctuations are not the same for all individuals, and there might be individuals who experience more fluctuations.

```{r}
for (participant in unique(data$ID)) {
  moods <- data %>%
    filter(!is.na(mood))
  
  mood <- moods %>% filter(ID == participant)
  
  p <- mood %>% ggplot(
    aes(x = date_time, 
        y = mood)) +
    geom_line(color = colors()[sample(8:length(colors()),1)]) + 
    scale_y_continuous(limits = c(1, 10)) +
    theme_classic(base_family = "Times") + 
    theme(legend.position = "none") +
    labs(title = paste(
      "Mood Over Time for Participant Number", 
      participant), 
         x = "Time", 
         y = "Mood")
  
  print(p)
}
```

Participant number 7 have too much fluctuations and can be considered an outlier among the other participants. It might possibly be a good idea to exclude them. Maybe also participant number 33.

```{r}
# Creating a new variable in our "mood_summary" 
# Putting the ID to the column if the participant is an outlier 
# FROM: https://www.r-bloggers.com/2022/08/how-to-label-outliers-in-boxplots-in-ggplot2/
find_outlier <- function(x) {
  return(x < quantile(x, .25) - 1.5*IQR(x) | x > quantile(x, .75) + 1.5*IQR(x))
}

mood_summary <- mood_summary %>% mutate(
  outlier = ifelse(find_outlier(sd_mood), ID, NA))
mood_summary$outlier[6] <- 7
mood_summary$outlier[27] <- 33

mood_summary %>% ggplot(aes(x = "", y = sd_mood)) +
  geom_boxplot(color = "firebrick") +
  theme_classic(base_family = "Times") +
  labs(title = "Boxplot of Standard Deviation of Mood",
       y = "Standard Deviation of Mood",
       x = "") + 
  geom_text(aes(label=outlier), na.rm=TRUE, hjust=-1)
```

Although, it needs to be noted that individuals who have depression will show these mood fluctuations. If we assume that this sample is a representative sample, considering the $10-20\%$ prevalence, we should expect around $2-4$ individuals that are displaying such patterns. Hence, it is a question whether this should actually be considered as an "anomaly". 



## Arousal & Valence
```{r}
# Quick Summary: Arousal
summary(data$circumplex.arousal)
table(data$circumplex.arousal)

# Quick Summary: Valence
summary(data$circumplex.valence)
table(data$circumplex.valence)

# Histograms
hist_arousal <- data %>% filter(!is.na(circumplex.arousal)) %>% 
  ggplot(aes(x = circumplex.arousal)) + 
  geom_histogram(bins = 5, color = "black", fill = "deepskyblue2") +
  theme_classic(base_family = "Times") + 
  labs(title = "Distribution of Arousal", 
       x = "Arousal", 
       y = "Frequency")
print(hist_arousal)

hist_valence <- data %>% filter(!is.na(circumplex.valence)) %>% 
  ggplot(aes(x = circumplex.valence)) + 
  geom_histogram(bins = 5, color = "black", fill = "purple2") +
  theme_classic(base_family = "Times") + 
  labs(title = "Distribution of Valence", 
       x = "Valence", 
       y = "Frequency")
print(hist_valence)
```

```{r}
(hist_mood | hist_arousal | hist_valence) + 
  patchwork::plot_layout(ncol = 3)
```


## Psychological x Hour
```{r}
hist_mood_hour <- data %>% filter(!is.na(mood)) %>% 
  ggplot(aes(x = hour)) + 
  geom_histogram(bins = 24, 
                 color = "black", 
                 fill = "firebrick") + 
  theme_classic(base_family = "Times") + 
  labs(title = "Frequency of Mood Observations Per Hour", 
       x = "Hour",
       y = "Frequency") + 
  scale_x_continuous(breaks = 0:23)

hist_arousal_hour <- data %>% filter(!is.na(circumplex.arousal)) %>% 
  ggplot(aes(x = hour)) + 
  geom_histogram(bins = 24, 
                 color = "black", 
                 fill = "deepskyblue2") + 
  theme_classic(base_family = "Times") + 
  labs(title = "Frequency of Arousal Observations Per Hour", 
       x = "Hour",
       y = "Frequency") + 
  scale_x_continuous(breaks = 0:23)

hist_valence_hour <- data %>% filter(!is.na(circumplex.valence)) %>% 
  ggplot(aes(x = hour)) + 
  geom_histogram(bins = 24, 
                 color = "black", 
                 fill = "purple2") + 
  theme_classic(base_family = "Times") + 
  labs(title = "Frequency of Valence Observations Per Hour", 
       x = "Hour",
       y = "Frequency") + 
  scale_x_continuous(breaks = 0:23)

(hist_mood | hist_arousal | hist_valence | 
 hist_mood_hour | hist_arousal_hour | hist_valence_hour) + 
  patchwork::plot_layout(ncol = 3, nrow = 2)
```




## Activity
```{r}
activity_count_per_hour <- data %>%
  filter(!is.na(activity)) %>%
  group_by(hour) %>%
  summarize(count = n())

# Bar Plot
activity_count_per_hour %>%
  ggplot(aes(
    x = hour, 
    y = count)) + 
  geom_col(color = "black", 
           fill = "orange") + coord_cartesian(ylim=c(700,900))
```


```{r}
activity_count_per_hour <- data %>%
  filter(activity == 0) %>%
  group_by(hour) %>%
  summarize(count = n())

# Bar Plot
activity_count_per_hour %>%
  ggplot(aes(
    x = hour, 
    y = count)) + 
  geom_col(color = "black", 
           fill = "orange")
```































# Adding Beeps

First assigning new rows with beeps to the dataset.
```{r}
# Generate additional times and beeps
additional_times <- c(
  "06:00:01", # ghost beep to mark night time
  "09:00:01", 
  "12:00:01", 
  "15:00:01", 
  "18:00:01", 
  "21:00:01")
beep_identifiers <- c(0, 1, 2, 3, 4, 5) 
dates <- unique(as.Date(data$date_time))
participants <- unique(data$ID)

# Map times to beep identifiers
time_to_beep <- setNames(beep_identifiers, additional_times)
# Create a data frame of all combinations of dates, times, and participants
expanded_data <- expand.grid(
  date = dates, 
  time = additional_times, 
  ID = participants)
expanded_data$date_time <- as.POSIXct(paste(
  expanded_data$date, 
  expanded_data$time))
expanded_data$beep_number <- time_to_beep[as.character(expanded_data$time)]

# Initialize columns for expanded_data that are in data but not in expanded_data
additional_columns <- setdiff(names(data), names(expanded_data))
for (col in additional_columns) {
  expanded_data[[col]] <- NA
}

# Combine original and expanded data
data$beep_number <- NA # since this variable does not exist in the original dataset
combined_data <- rbind(data, expanded_data)

# Remove duplicate rows and sort by date_time
combined_data <- combined_data %>%
  arrange(ID, date_time) %>%
  distinct()

# Make sure it is sorted by ID and date_time
combined_data <- combined_data %>%
  arrange(ID, date_time)

# Fill beep_number NA values using zoo::na.locf()
combined_data$beepo <- zoo::na.locf(
  combined_data$beep_number, 
  na.rm = FALSE, 
  fromLast = TRUE)

### THE OTHER WAY:: ###
#combined_data$beepo2 <- zoo::na.locf(
#  combined_data$beep_number, 
#  na.rm = FALSE)
```


```{r}
combined_data_clean <- clean_id_time(combined_data)
```


```{r}
# Create a flag that identifies each transition from beep 5 to beep 0
combined_data_clean <- combined_data_clean %>%
  group_by(ID) %>% mutate(
    new_day_flag = if_else(lag(beepo, default = first(beepo)) == 5 & beepo == 0, 1, 0),
    # Cumulatively sum these flags to identify unique observation days for each participant
    observation_day = cumsum(new_day_flag)) %>%
  ungroup()
```


```{r}
combined_data_clean_removed_obs_day_0 <- combined_data_clean %>% 
  filter(observation_day != 0) %>% subset(select = -new_day_flag)
```

```{r}
data <- combined_data_clean_removed_obs_day_0
# x <- data
```

# --------------------


# Sleep

```{r}
data_beepo_0 <- combined_data_clean_removed_obs_day_0 %>% filter(
  beepo == 0 | (time == "21:00:01" & is.na(obs_number)))
```


```{r}
# Sort data by date_time
data_beepo_0 <- data_beepo_0 %>% arrange(ID, date_time)
```


## Potential Sleep Gap
```{r}
# Column for the time difference between 
# the current observation and the last observation
data_beepo_0 <- data_beepo_0 %>% 
  group_by(ID, observation_day) %>% mutate(
  # For every observation, getting the difference between the previous
  time_diff = round(
    difftime(date_time, lag(date_time),
             units = "hours"), 3),
  # If it is 15, then make it 9, for looking at sleep later
  time_diff_adj = ifelse(time_diff == 15, 0, time_diff),
  # Gap based on both these variables
  possible_sleep_gap = (time_diff_adj > 1 & time_diff_adj <= 9),
  time_diff_valid = ifelse(
    possible_sleep_gap, time_diff_adj, 0)
  ) %>% 
  ungroup()
```

## Inactivity

```{r}
# Inactivity
data_beepo_0 <- data_beepo_0 %>% mutate(
  is_inactive = dplyr::case_when(
    is.na(activity) ~ FALSE,
    activity == 0 ~ TRUE,
    TRUE ~ FALSE))

# Applying a run-length encoding to count consecutive inactive periods
data_beepo_0 <- data_beepo_0 %>% group_by(ID) %>% mutate(
    consecutive_inactive = with(rle(is_inactive), {
      # Only count lengths where is_inactive is TRUE:
      lengths_corrected <- lengths * values  
      # Repeat these lengths according to run lengths:
      rep(lengths_corrected, lengths)   
    })) %>% 
  ungroup()

# Getting rid of the consequitve duplicates so that summing up later is easier.
data_beepo_0 <- data_beepo_0 %>%
  mutate(
    # Use lag to compare each value to the previous, 
    # initializing the first comparison to TRUE
    consecutive_inactive_fix = if_else(
      consecutive_inactive != lead(
        consecutive_inactive, 
        default = consecutive_inactive[n()]+1), 
      (consecutive_inactive - 1), 0),
    
    consecutive_inactive_fix = if_else(
      consecutive_inactive_fix == -1,
      0,
      consecutive_inactive_fix)
  )

table(data_beepo_0$consecutive_inactive_fix)
```

```{r}
aggregated_night_data <- data_beepo_0 %>%
  group_by(ID, observation_day) %>%
  summarise(
    night_mood = safe_mean(mood),
    night_arousal = safe_mean(circumplex.arousal),
    night_valence = safe_mean(circumplex.valence),
    
    night_physical_activity = safe_mean(activity),
    
    night_screen = sum(screen, na.rm = T),
    
    night_appcat_combined = sum(
      appCat.builtin,
      appCat.communication,
      appCat.entertainment,
      appCat.finance,
      appCat.game,
      appCat.office,
      appCat.other,
      appCat.social,
      appCat.travel,
      appCat.unknown,
      appCat.utilities,
      appCat.weather, na.rm = T),
    
    total_time_diff = safe_sum(time_diff_valid),
    max_time_diff = max(time_diff_valid, na.rm = T),
    
    total_inactivity = safe_sum(consecutive_inactive_fix),
    max_inactivity = max(consecutive_inactive_fix, na.rm = T),
    
    SUM_inactivity_timediff = sum(
      total_inactivity, 
      total_time_diff, 
      na.rm = T),
    
    MAX_inactivity_timediff = max(
      max_time_diff, 
      max_inactivity, 
      na.rm = T),
    .groups = "drop")
```


# Aggregating Data

```{r}
aggregated_data <- combined_data_clean_removed_obs_day_0 %>%
  group_by(ID, observation_day, beepo) %>%
  summarise(
    date = max(date),
    mood = mean(mood, na.rm = TRUE),
    arousal = mean(circumplex.arousal, na.rm = TRUE),
    valence = mean(circumplex.valence, na.rm = TRUE),
    activity = mean(activity, na.rm = TRUE),
    screen = sum(screen, na.rm = TRUE),
    call = sum(call, na.rm = TRUE),
    sms = sum(sms, na.rm = TRUE),
    appCat.builtin = sum(appCat.builtin, na.rm = TRUE),
    appCat.communication = sum(appCat.communication, na.rm = TRUE),
    appCat.entertainment = sum(appCat.entertainment, na.rm = TRUE),
    appCat.finance = sum(appCat.finance, na.rm = TRUE),
    appCat.game = sum(appCat.game, na.rm = TRUE),
    appCat.office = sum(appCat.office, na.rm = TRUE),
    appCat.other = sum(appCat.other, na.rm = TRUE),
    appCat.social = sum(appCat.social, na.rm = TRUE),
    appCat.travel = sum(appCat.travel, na.rm = TRUE),
    appCat.unknown = sum(appCat.unknown, na.rm = TRUE),
    appCat.utilities = sum(appCat.utilities, na.rm = TRUE), 
    appCat.weather = sum(appCat.weather, na.rm = TRUE), 
    .groups = "drop")
```


```{r}
data_with_night <- aggregated_data %>%
  left_join(aggregated_night_data, by = c("ID", "observation_day")) %>% 
  filter(beepo != 0)
```

NIGHT MOOD REPLACING
```{r}
data_with_night <- data_with_night %>%
  arrange(ID, observation_day, beepo) %>%
  group_by(ID) %>% mutate(
    # Create lagged versions of night variables to fill backwards
    lead_night_mood = if_else(
      beepo == 5, 
      lead(night_mood, default = first(night_mood)), 
      NA_real_),
    
    lead_night_arousal = if_else(
      beepo == 5, 
      lead(night_arousal, default = first(night_arousal)),
      NA_real_),
    
    lead_night_valence = if_else(
      beepo == 5, 
      lead(night_valence, default = first(night_valence)), 
      NA_real_)) %>% ungroup()

data_with_night <- data_with_night %>% mutate(
    mood = case_when(
      beepo == 5 & is.na(mood) ~ lead_night_mood,
      beepo == 5 & !is.na(mood) & !is.na(lead_night_mood) ~ 
        (mood + lead_night_mood)/2,
      TRUE ~ mood
    ),
    arousal = case_when(
      beepo == 5 & is.na(arousal) ~ lead_night_arousal,
      beepo == 5 & !is.na(arousal) & !is.na(lead_night_arousal) ~ 
        (arousal + lead_night_arousal)/2,
      TRUE ~ arousal
    ),
    valence = case_when(
      beepo == 5 & is.na(valence) ~ lead_night_valence,
      beepo == 5 & !is.na(valence) & !is.na(lead_night_valence) ~ 
        (valence + lead_night_valence)/2,
      TRUE ~ valence)
    )
```


```{r}
data <- data_with_night
```


choosing night variables and some cleaning 
```{r}
data <- data %>% subset(
  select = -c(night_mood, night_arousal, night_valence,
              total_time_diff, max_time_diff, 
              total_inactivity, max_inactivity,
              MAX_inactivity_timediff, 
              lead_night_mood, lead_night_arousal, lead_night_valence))

# Creating Variable: the day of the week (of Observation)
data <- data %>%
  mutate(weekday = weekdays(date),
         weekday = as.numeric(factor(
           weekday,
           labels = 1:7,
           levels = c("Monday", "Tuesday", 
                      "Wednesday", "Thursday", 
                      "Friday", "Saturday", 
                      "Sunday"))))

# Creating Variable: the week of the year (of Observation)
data <- data %>%
  mutate(week_of_year = lubridate::week(date))
```


# ---------------

# Outliers and Log Transform
```{r}
for (i in names(data)) {
  if (is.numeric(data[[i]])) {
    boxplot(data[[i]], main = i)
  }
}

```


```{r}
for (i in names(data)) {
  if (is.numeric(data[[i]])) {
    hist(data[[i]], main = i)
    hist(log(data[[i]]), main = i)
  }
}
```



```{r}
data_log_transform <- data
# Columns to log-transform
columns_to_log_transform <- c(
  "activity",
  "screen", "appCat.builtin", "appCat.communication",
  "appCat.entertainment", "appCat.finance", "appCat.game",
  "appCat.office", "appCat.other", "appCat.social",
  "appCat.travel", "appCat.unknown", "appCat.utilities", 
  "appCat.weather", 
  "night_physical_activity", "night_screen", 
  "night_appcat_combined")

# Apply log transformation to selected columns
# log1p for handling zero by adding 1
data_log_transform[columns_to_log_transform] <-
  lapply(data_log_transform[columns_to_log_transform], log1p)
```

```{r}
log1p()
hist((data_log_transform$appCat.builtin))
```


```{r}
data_normal <- data %>%
  mutate_at(vars(activity:night_appcat_combined), scale)
```


```{r}
# Fitting a linear model with the same fixed effects
lm_model <- lm(mood ~ arousal + valence + activity + screen + call + sms +
               appCat.builtin + appCat.communication + appCat.entertainment +
               appCat.finance + appCat.game + appCat.office + appCat.other +
               appCat.social + appCat.travel + appCat.unknown + appCat.utilities +
               appCat.weather + night_physical_activity + night_screen +
               night_appcat_combined + SUM_inactivity_timediff + weekday +
               week_of_year, data = data)

# Calculating VIF for the linear model
car::vif(lm_model)

```


```{r}
data$week_of_year
model <- lme4::lmer(
  mood ~ 
    arousal + valence +
    activity + screen + 
    call + sms + 
    appCat.builtin + appCat.communication + 
    appCat.entertainment + appCat.finance + 
    appCat.game + appCat.office + appCat.other + 
    appCat.social + appCat.travel + appCat.unknown + 
    appCat.utilities + appCat.weather + night_physical_activity + 
    night_screen + night_appcat_combined + SUM_inactivity_timediff + 
    weekday + week_of_year + 
    (1|ID/observation_day), 
  data=data)
summary(model)
car::vif(model)

model <- lmerTest::lmer(mood ~ 
    arousal + valence +
    activity + screen + 
    call + sms + 
    appCat.builtin + appCat.communication + 
    appCat.entertainment + appCat.finance + 
    appCat.game + appCat.office + appCat.other + 
    appCat.social + appCat.travel + appCat.unknown + 
    appCat.utilities + appCat.weather + night_physical_activity + 
    night_screen + night_appcat_combined + SUM_inactivity_timediff + 
    weekday + week_of_year + 
    (1|ID/observation_day), 
  data=data)
```








# ---------



# Train-test Split

## Time
Based on time
```{r}
test_days <- length(unique(data$date)) * (1/5)

data_TRAIN_time <- data %>% filter(date <= max(data$date) - test_days)
length(unique(data_TRAIN_time$date))


data_TEST_time <- data %>% filter(date > max(data$date) - test_days)
length(unique(data_TEST_time$date))
```

## EXPORT DATA_2 - TIME
```{r}
data_to_write_TRAIN <- fix_time(data_TRAIN_time)
write.csv(data_to_write_TRAIN, "data/data_2_TRAIN_TIME_not_aggregated.csv")

data_to_write_TEST <- fix_time(data_TEST_time)
write.csv(data_to_write_TEST, "data/data_2_TEST_TIME_not_aggregated.csv")
```


## Participant
Based on participant

```{r}
participants <- unique(data$ID)
set.seed(11042024) # Setting random seed with the date
test_participants <- sample(participants, length(participants)* 1/5)
test_participants

data_TEST_id <- data %>% filter(ID %in% test_participants)
unique(as.numeric(data_TEST_id$ID))

`%not_in%` <- purrr::negate(`%in%`)
data_TRAIN_id <- data %>% dplyr::filter(ID %not_in% test_participants)
unique(as.numeric(data_TRAIN_id$ID))
```

## EXPORT DATA_2 - ID
```{r}
data_to_write_TRAIN <- fix_time(data_TRAIN_id)
write.csv(data_TRAIN_id, "data/data_2_TRAIN_ID_aggregated_beep.csv")

data_to_write_TEST <- fix_time(data_TEST_id)
write.csv(data_TEST_id, "data/data_2_TEST_ID_aggregated_beep.csv")
```


# ---------
```{r}
data <- data_TRAIN_id
```


# MICE

Checking NAs in all data
```{r}
for(col in colnames(data)){
  print(sum(is.na(data[[col]])))
}
```


```{r}
# x <- data
# devtools::install_github(repo = "amices/mice")

impmethod <- character(ncol(data))
names(impmethod) <- colnames(data)
impmethod["valence"] <- "pmm"
pm <- mice::make.predictorMatrix(data)
pm["valence", c(
  "ID", "observation_day", "beepo", 
  "arousal", "mood", 
  "activity", "night_physical_activity")] <- c(
    -2, -2, -2, 
    0, 0, 
    0, 0)
# run multiple imputations
res.mice.md <- mice(
  data, 
  predictorMatrix = pm,
  method=impmethod, 
  maxit=10)
data <- mice::complete(res.mice.md)




impmethod <- character(ncol(data))
names(impmethod) <- colnames(data)
impmethod["arousal"] <- "pmm"
pm <- mice::make.predictorMatrix(data)
pm["arousal", c(
  "ID", "observation_day", "beepo", 
  "mood", 
  "activity", "night_physical_activity")] <- c(
    -2, -2, -2, 
    0, 
    0, 0)
# run multiple imputations
res.mice.md <- mice(
  data, 
  predictorMatrix = pm,
  method=impmethod, 
  maxit=10)
data <- mice::complete(res.mice.md)




impmethod <- character(ncol(data))
names(impmethod) <- colnames(data)
impmethod["activity"] <- "pmm"
pm <- mice::make.predictorMatrix(data)
pm["activity", c(
  "ID", "observation_day", "beepo", 
  "mood", 
  "night_physical_activity")] <- c(
    -2, -2, -2, 
    0, 
    0)
# run multiple imputations
res.mice.md <- mice(
  data, 
  predictorMatrix = pm,
  method=impmethod, 
  maxit=10)
data <- mice::complete(res.mice.md)



impmethod <- character(ncol(data))
names(impmethod) <- colnames(data)
impmethod["night_physical_activity"] <- "pmm"
pm <- mice::make.predictorMatrix(data)
pm["night_physical_activity", c(
  "ID", "observation_day", "beepo", 
  "mood")] <- c(
    -2, -2, -2, 
    0)
# run multiple imputations
res.mice.md <- mice(
  data, 
  predictorMatrix = pm,
  method=impmethod, 
  maxit=10)
data <- mice::complete(res.mice.md)





impmethod <- character(ncol(data))
names(impmethod) <- colnames(data)
impmethod["mood"] <- "pmm"
pm <- mice::make.predictorMatrix(data)
pm["mood", c(
  "ID", "observation_day", "beepo")] <- c(
    -2, -2, -2)
# run multiple imputations
res.mice.md <- mice(
  data, 
  predictorMatrix = pm,
  method=impmethod, 
  maxit=10)
data <- mice::complete(res.mice.md)
```

```{r}
imputed_data <- data
```


# ---------

```{r}
aggregate_data_by_day <- imputed_data %>%
  group_by(ID, date) %>%
  summarise(
    observation_day = max(observation_day),
    mood = mean(mood, na.rm = TRUE),
    arousal = mean(arousal, na.rm = TRUE),
    valence = mean(valence, na.rm = TRUE),
    activity = mean(activity, na.rm = TRUE),
    screen = sum(screen, na.rm = TRUE),
    call = sum(call, na.rm = TRUE),
    sms = sum(sms, na.rm = TRUE),
    appCat.builtin = sum(appCat.builtin, na.rm = TRUE),
    appCat.communication = sum(appCat.communication, na.rm = TRUE),
    appCat.entertainment = sum(appCat.entertainment, na.rm = TRUE),
    appCat.finance = sum(appCat.finance, na.rm = TRUE),
    appCat.game = sum(appCat.game, na.rm = TRUE),
    appCat.office = sum(appCat.office, na.rm = TRUE),
    appCat.other = sum(appCat.other, na.rm = TRUE),
    appCat.social = sum(appCat.social, na.rm = TRUE),
    appCat.travel = sum(appCat.travel, na.rm = TRUE),
    appCat.unknown = sum(appCat.unknown, na.rm = TRUE),
    appCat.utilities = sum(appCat.utilities, na.rm = TRUE), 
    appCat.weather = sum(appCat.weather, na.rm = TRUE), 
    night_physical_activity = mean(night_physical_activity),
    night_screen = mean(night_screen),
    night_appcat_combined = mean(night_appcat_combined),
    SUM_inactivity_timediff = mean(SUM_inactivity_timediff),
    weekday = max(weekday),
    week_of_year = max(week_of_year),
    .groups = "drop")

colnames(aggregate_data_by_day)[1] = "id"
colnames(aggregate_data_by_day)[2] = "datetime"
```


```{r}
write.csv(aggregate_data_by_day,"data/data_4_aggregated_day.csv")
```


# Creating Mood Lags






DAY:
```{r}
# Calculating the Daily Average Mood
daily_moods <- data %>%
  group_by(ID, observation_day) %>%
  summarise(daily_average_mood = mean(mood, na.rm = TRUE), .groups = 'drop')

# Join the daily averages back to the original data 
# and then calculate the average mood for the next day
data <- data %>%
  left_join(daily_moods, by = c("ID", "observation_day")) %>% 
  group_by(ID) %>% 
  mutate(mood_of_next_day = lead(daily_average_mood, n=5)) %>%
  ungroup()
```

BEEP:
```{r}
data <- data %>% 
  group_by(ID) %>% 
  mutate(
    mood_of_next_beep = lead(mood)
)
```





```{r}
write.csv(data, "data/data_3_imputed_aggregated_beeps.csv")
```




```{r}

```

















Then aggregating the dataset based on beeps.
```{r}
# Example aggregation: Calculate the mean mood for each beep interval for each participant
# You can change this to match the specific columns and summary statistics you need
aggregated_data <- combined_data %>%
  group_by(ID, beep_number) %>%
  summarize(mean_mood = mean(mood, na.rm = TRUE), .groups = 'drop')

```


```{r}
write.csv(aggregated_data, "data/data_3_aggregated_BEEPS.csv")
```















# Imputation
## Kalman
```{r}
imputed <- imputeTS::na_kalman(aggregated_data)
```

```{r}
write.csv(imputed, "data_3_imputed_kalman.csv")
```


# Normalization

```{r}
data_normal <- imputed %>%
  mutate_at(vars(arousal:appCat.weather), scale)
```







# Sleep


```{r}
# data <- combined_data
```


```{r}
# 21 - 12
data <- data %>% filter(beepo2 == 5 | beepo2 == 1)
```


## Observation Day
```{r}
# Adding a days_since_start column
data <- data %>% mutate(
  days_since_start = as.numeric(
    difftime(date, min(date), units = "days")))

# Check
unique(data$days_since_start)
```

```{r}
# Sort data by date_time
data <- data %>% arrange(ID, date_time)
```

```{r}
# Potential Hours 
data <- data %>% mutate(
  after_midnight_activity = (hour >= 0 & hour <= 6),
  # Wake up Hour (first observation after the difference)
  potential_sleep_hour = (hour >= 20 | hour <= 11),
  # Wake up Hour (first observation after the difference)
  potential_wakeup_hour = (hour >= 5 & hour <= 12))
```

## Potential Sleep Gap
```{r}
# Column for the time difference between 
# the current observation and the last observation
data <- data %>% group_by(ID) %>% mutate(
  # For every observation, getting the difference between the previous
  time_diff = round(
    difftime(date_time, lag(date_time),
             units = "hours"), 3),
  # Gap based on both these variables
  possible_sleep_gap = (time_diff >= 5 & time_diff <= 15) & 
    (potential_wakeup_hour == TRUE)) %>% 
  ungroup()
```

## Inactivity
```{r}
# Inactivity
data <- data %>% mutate(
  is_inactive = dplyr::case_when(
    is.na(activity) ~ FALSE,
    activity == 0 ~ TRUE,
    TRUE ~ FALSE))

# Applying a run-length encoding to count consecutive inactive periods
data <- data %>% group_by(ID) %>% mutate(
    consecutive_inactive = with(rle(is_inactive), {
      # Only count lengths where is_inactive is TRUE:
      lengths_corrected <- lengths * values  
      # Repeat these lengths according to run lengths:
      rep(lengths_corrected, lengths)   
    })) %>% 
  ungroup()
```

## Fragmented Sleep
```{r}
########  1  #############
# last inactive hour
data <- data %>%
  mutate(
    # Check if current observation is inactive
    last_inactive_hour = if_else(is_inactive, hour, 
                                            NA_integer_)
  ) %>%
  group_by(ID) %>%
  # Fill NA values with the last known inactive hour, carrying it forward
  fill(last_inactive_hour, .direction = "down") %>%
  ungroup()

########  2  ##########
# Assuming data is already loaded and date_time is in POSIXct format
data <- data %>%
  mutate(
    # Record the datetime of the last inactive observation
    last_inactive_time = if_else(is_inactive, date_time, as.POSIXct(NA))
  ) %>%
  group_by(ID) %>%
  # Fill NA values with the last known inactive datetime, carrying it forward
  fill(last_inactive_time, .direction = "down") %>%
  ungroup() %>%
  mutate(
    # Calculate the time difference in hours between now and the last inactive time
    time_since_last_inactive = if_else(is.na(last_inactive_time),
                                       NA_real_,
                                       as.numeric(difftime(date_time, last_inactive_time, units = "hours")))
  )
```


## WORKING ON IT NOW
```{r}
# Determine if sleep occurred after midnight
data <- data %>% mutate(
    slept_after_midnight = hour(date_time) >= 0 & hour(date_time) <= 6 & sleep == 1)

```




## Sleep
```{r}
data <- data %>% group_by(ID)%>% mutate(
  sleep = case_when(
    consecutive_inactive >= 4 & 
      potential_sleep_hour ~ consecutive_inactive, 
    
    possible_sleep_gap & 
      potential_wakeup_hour ~ round(as.numeric(time_diff)),
    
    TRUE ~ 0
  )
) %>% ungroup()
```










# Aggregating

```{r}
# aggregating the data by date, for all participants
aggregated_data <- data %>%
  group_by(date, ID) %>%
  summarise(
    mood = mean(mood, na.rm = TRUE),
    arousal = mean(circumplex.arousal, na.rm = TRUE),
    valence = mean(circumplex.valence, na.rm = TRUE),
    activity = mean(activity, na.rm = TRUE),
    # screen???
    call = sum(call, na.rm = TRUE),
    sms = sum(sms, na.rm = TRUE),
    appCat.builtin = sum(appCat.builtin, na.rm = TRUE),
    appCat.communication = sum(appCat.communication, na.rm = TRUE),
    appCat.entertainment = sum(appCat.entertainment, na.rm = TRUE),
    appCat.finance = sum(appCat.finance, na.rm = TRUE),
    appCat.game = sum(appCat.game, na.rm = TRUE),
    appCat.office = sum(appCat.office, na.rm = TRUE),
    appCat.other = sum(appCat.other, na.rm = TRUE),
    appCat.social = sum(appCat.social, na.rm = TRUE),
    appCat.travel = sum(appCat.travel, na.rm = TRUE),
    appCat.unknown = sum(appCat.unknown, na.rm = TRUE),
    appCat.utilities = sum(appCat.utilities, na.rm = TRUE), 
    appCat.weather = sum(appCat.weather, na.rm = TRUE), 
    .groups = "drop")

# Standardizing
aggregated_data_2 <- aggregated_data %>%
  mutate_at(vars(arousal:appCat.weather), scale)
colnames(aggregated_data_2)

# Model
model <- lme4::lmer(
  mood ~ arousal + 
    valence + 
    activity + 
    call + 
    sms + 
    appCat.builtin + 
    appCat.communication + 
    appCat.entertainment + 
    appCat.finance + 
    appCat.game + 
    appCat.office + 
    appCat.other + 
    appCat.social + 
    appCat.travel + 
    appCat.unknown + 
    appCat.utilities + 
    appCat.weather + 
    (1 + time|ID), 
  data = aggregated_data)
summary(model)
```


```{r}
write.csv(aggregated_data, "data_aggregated.csv")
```




# Network Shit

```{r}
load("ml_mod.RData")
```

```{r}
variables_network <- c("mood", "arousal", "valence", "activity", "call", "sms", "appCat.builtin", "appCat.communication", "appCat.entertainment", "appCat.finance", "appCat.game", "appCat.office", "appCat.other", "appCat.social", "appCat.travel", "appCat.unknown", "appCat.utilities", "appCat.weather")

data_normal <- read.csv("data_for_analysis.csv")

variables_network <- c("mood", "arousal", "valence", "activity", "appCat.social")
# "call", "sms", "appCat.communication", "appCat.entertainment", "appCat.finance", "appCat.game", 

# multilevel vector autoregressive (mlVAR) model, 
# also regarded as a special case of the dynamic structural equation model (DSEM)
library(mlVAR)
ml_mod <- mlVAR::mlVAR(
  data_normal, 
  vars = variables_network, 
  idvar = "ID", 
  dayvar = "date", 
  estimator = "lmer", 
  beepvar = "beepo", 
  temporal = "correlated", 
  contemporaneous = "correlated")
```


```{r}
temp <- plot(ml_mod, 
             "temporal", 
             title="Temporal Network",
             layout = "circle")

plot(ml_mod, "contemporaneous", title="Contemporaneous Network", rule = "and")

plot(ml_mod, "between", title="Between-Subject Network", rule = "and")

summary(ml_mod)
```



```{r}
# Assume ml_mod is already fitted
temp <- plot(ml_mod, 
             plotType = "temporal", 
             title = "Temporal Network",
             layout = layout_in_circle)  # Using igraph's layout

# Enhance plot aesthetics using igraph's options
plot.igraph(temp,
            main = "Temporal Network",
            vertex.label.color = "darkblue",
            vertex.label.cex = 0.8,  # Control label size
            vertex.size = 20,
            edge.arrow.size = 0.5,
            layout = layout_in_circle(temp))

temp <- mlVAR::plot(ml_mod, 
                    plotType = "temporal", 
                    title = "Temporal Network",
                    layout = "circle",
                    labels = TRUE,      # Ensure labels are shown if needed
                    edge.color = "black",
                    edge.width = 2,
                    vsize = 5,
                    color = "skyblue")


qgraph::qgraph(adj_matrix,
       layout = "circle",
       labels = colnames(adj_matrix),  # Ensure you have column names for labels
       title = "Temporal Network",
       edge.color = "black",
       edge.width = 2,
       vsize = 5,
       color = "skyblue") 
```







# Bayes stuff

```{r}
# mHMMbayes::

model <- mHMMbayes::mHMM(
  y = list(mood = aggregated_data$mood), # Add other response variables as needed
  id = aggregated_data$ID, 
  data = aggregated_data, 
  n_states = 3, # Example: 3 hidden states
  covars = list("trans" = ~ arousal + valence) # Example covariates for transitions
)
?mHMMbayes::mHMM
# Initial values (hypothetical)
start_values <- list(
  startProbs = rep(1/3, 3),
  transProbs = matrix(c(.8, .1, .1, .1, .8, .1, .1, .1, .8), nrow = 3),
  emissionProbs = list(mood = rep(1/3, 3))
)

# Fit the model
fitted_model <- fit_model(model, start_values = start_values, iter = 10000, burnin = 1000)

# Check results
summary(fitted_model)
```


# Clustering
```{r}
data <- data %>% mutate(
  mood_cat = )
```








