---
title: "Mood"
author: "Arda Ergin"
date: "2024-04-02"
output: html_document
---

```{r}
source("requirements.R")
load("R_code_2.RData")
```


```{r}
data <- data %>% subset(select= -c(
  appCat.weather, 
  appCat.utilities, 
  appCat.unknown, 
  appCat.other))
```


We have two types of variables:       
1) For the recorded variables, there are no missing values, hence we can log-transform and scale them without imputation.         
2) for mood, arousal, valence, activity, we need to first impute them, then scale them, since they do have missing values.

```{r}
zip_model <- zeroinfl(
  formula = mood ~ Predictor1 + Predictor2 | Predictor1 + Predictor2, 
  data = data_log_transform, 
  dist = "poisson")
```



# Outliers and Log Transform
```{r}
for (i in names(data)) {
  if (is.numeric(data[[i]])) {
    boxplot(data[[i]], main = i)
  }
}

```

```{r}
summary(model)
```



```{r}
for (i in names(data)) {
  if (is.numeric(data[[i]])) {
    hist(data[[i]], main = i)
    hist(log1p(data[[i]]), main = i)
  }
}
```

screen, builtin, communication,
night screen

choose: night screen or appcat combined

social
entertain
finance, travel
game, office, 

call, sms



```{r}


sum(data$appCat.game==0)
# 5500 / 5750 played


boxplot_game <- data %>% ggplot(aes(x = "", y = appCat.game)) +
  geom_boxplot(color = "forestgreen") +
  theme_classic(base_family = "Times") +
  labs(title = "Boxplot of App Category 'game'",
       y = "appCat.game Scores",
       x = "")

data %>% ggplot(aes(x = log1p(appCat.game))) +
  geom_histogram(color = "forestgreen", fill = "forestgreen", bins = 30) +  # You can adjust the number of bins
  theme_classic(base_family = "Times") +
  labs(title = "Histogram of Log-transformed App Category 'game' Scores",
       y = "Count",
       x = "Log-transformed appCat.game Scores")

hist(log1p(data$appCat.game))

```

```{r}
x <- car::yjPower(data$screen, lambda = 0.20)
x <- car::yjPower(data$appCat.communication, lambda = 0.1)
```


```{r}
sum(data$comm == 10, na.rm=T)
(data$call == 0)
x <- car::yjPower(data$night_physical_activity, lambda = 0.01)
par(mfrow = c(1,3))
hist(x)
hist((data$night_physical_activity))
hist(log1p(data$night_physical_activity))
```






```{r}
data_log_transform <- data

# Columns to log-transform
columns_to_log_transform <- c(
  # "activity", "night_physical_activity",
  "screen", "appCat.builtin", "appCat.communication",
  "appCat.entertainment", "appCat.finance", "appCat.game",
  "appCat.office", "appCat.other", "appCat.social",
  "appCat.travel", "appCat.unknown", "appCat.utilities", 
  "appCat.weather", 
  "night_screen", 
  "night_appcat_combined")

# 
for (col in columns_to_log_transform) {
  data_log_transform[[paste0("binary_", col)]] <- as.integer(data_log_transform[[col]] > 0)
}

# Apply log transformation to selected columns
# log1p for handling zero by adding 1
data_log_transform[columns_to_log_transform] <-
  lapply(data_log_transform[columns_to_log_transform], log1p)
```


```{r}
columns_to_log_transform <- c(
  # "activity", "night_physical_activity",
  "screen", "appCat.builtin", "appCat.communication",
  "appCat.entertainment", "appCat.finance", "appCat.game",
  "appCat.office", "appCat.other", "appCat.social",
  "appCat.travel", "appCat.unknown", "appCat.utilities", 
  "appCat.weather", 
  "night_screen", 
  "night_appcat_combined"
)

# Log-transform and create binary indicator
data_log_transform <- data_log_transform %>%
  mutate(across(all_of(columns_to_log_transform), ~log1p(.), .names = "log_{.col}")) %>%
  mutate(across(all_of(columns_to_log_transform), ~as.integer(. > 0), .names = "binary_{.col}"))

# Normalize the log-transformed variables, replace 0 with NA, and impute NAs with the mean
data_log_transform <- data_log_transform %>%
  mutate(across(starts_with("log_"), ~{
    # Replace 0 with NA
    .x <- ifelse(.x == 0, NA, .x)
    # Calculate mean without NA
    mean_val <- mean(.x, na.rm = TRUE)
    # Normalize non-NA values
    .x <- ifelse(!is.na(.x), (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE), .x)
    # Replace NA with mean
    .x <- ifelse(is.na(.x), mean_val, .x)
  }))


```


```{r}
# Specifying the columns to transform
columns_to_log_transform <- c(
  # "activity", "night_physical_activity",
  "screen", "appCat.builtin", "appCat.communication",
  "appCat.entertainment", "appCat.finance", "appCat.game",
  "appCat.office", "appCat.other", "appCat.social",
  "appCat.travel", "appCat.unknown", "appCat.utilities", 
  "appCat.weather", 
  "night_screen", 
  "night_appcat_combined"
)

# Step 1: Log-transform the specified columns
for (col in columns_to_log_transform) {
  # Apply log1p transformation
  data_log_transform[[paste0("log_", col)]] <- log1p(data_log_transform[[col]])
}

# Step 2: Create binary indicators for the specified columns

```

```{r}

# Step 3: Normalize log-transformed variables and handle zeros
for (col in columns_to_log_transform) {
  log_col <- paste0("log_", col)
  
  # Replace 0 with NA for log-transformed column
  data_log_transform[[log_col]][data_log_transform[[log_col]] == 0] <- NA
  
  # Calculate mean of the log-transformed column, excluding NA
  mean_val <- mean(data_log_transform[[log_col]], na.rm = TRUE)
  
  # Calculate standard deviation of the log-transformed column, excluding NA
  sd_val <- sd(data_log_transform[[log_col]], na.rm = TRUE)
  
  # Normalize the log-transformed column, excluding NA
  data_log_transform[[log_col]] <- ifelse(
    !is.na(data_log_transform[[log_col]]),
    (data_log_transform[[log_col]] - mean_val) / sd_val,
    data_log_transform[[log_col]]
  )
  
  # Replace NA with mean of the normalized log-transformed values
  data_log_transform[[log_col]][is.na(data_log_transform[[log_col]])] <- 0
}
for (i in names(data_log_transform)) {
  if (is.numeric(data_log_transform[[i]])) {
    hist(data_log_transform[[i]], main = i)
  }
}X
```




```{r}
library(glmmTMB)
data_log_transform$SUM_inactivity_timediff
# Let's say you have a random effect 'random_effect_var' which is a grouping factor like a subject ID or a site ID.
zip_mixed_model <- glmmTMB::glmmTMB(
  mood ~ arousal + valence + 
    appCat.builtin + appCat.communication + appCat.entertainment + 
    week_of_year + weekday + SUM_inactivity_timediff + (1 | ID), 
  zi=~ appCat.builtin + appCat.communication + appCat.entertainment, 
  data = data_log_transform, 
    family = nbinom1)

```



```{r}
data_normal <- data %>%
  mutate_at(vars(activity:night_appcat_combined), scale)
```


```{r}
# Fitting a linear model with the same fixed effects
lm_model <- lm(mood ~ arousal + valence + activity + screen + call + sms +
               appCat.builtin + appCat.communication + appCat.entertainment +
               appCat.finance + appCat.game + appCat.office + appCat.other +
               appCat.social + appCat.travel + appCat.unknown + appCat.utilities +
               appCat.weather + night_physical_activity + night_screen +
               night_appcat_combined + SUM_inactivity_timediff + weekday +
               week_of_year, data = data)

# Calculating VIF for the linear model
car::vif(lm_model)

```


```{r}
data$week_of_year
model <- lme4::lmer(
  mood ~ 
    arousal + valence +
    activity + screen + 
    call + sms + 
    appCat.builtin + appCat.communication + 
    appCat.entertainment + appCat.finance + 
    appCat.game + appCat.office + appCat.other + 
    appCat.social + appCat.travel + appCat.unknown + 
    appCat.utilities + appCat.weather + night_physical_activity + 
    night_screen + night_appcat_combined + SUM_inactivity_timediff + 
    weekday + week_of_year + 
    (1|ID/observation_day), 
  data=data)
summary(model)
car::vif(model)

model <- lmerTest::lmer(mood ~ 
    arousal + valence +
    activity + screen + 
    call + sms + 
    appCat.builtin + appCat.communication + 
    appCat.entertainment + appCat.finance + 
    appCat.game + appCat.office + appCat.other + 
    appCat.social + appCat.travel + appCat.unknown + 
    appCat.utilities + appCat.weather + night_physical_activity + 
    night_screen + night_appcat_combined + SUM_inactivity_timediff + 
    weekday + week_of_year + 
    (1|ID/observation_day), 
  data=data)
```








# ---------



# Train-test Split on ID

Based on participant

```{r}
participants <- unique(data$ID)
set.seed(11042024) # Setting random seed with the date
test_participants <- sample(participants, length(participants)* 1/5)
test_participants

data_TEST_id <- data %>% filter(ID %in% test_participants)
unique(as.numeric(data_TEST_id$ID))

`%not_in%` <- purrr::negate(`%in%`)
data_TRAIN_id <- data %>% dplyr::filter(ID %not_in% test_participants)
unique(as.numeric(data_TRAIN_id$ID))
```

```{r}
# data_to_write_TRAIN <- fix_time(data_TRAIN_id)
write.csv(data_TRAIN_id, "data/data_2_TRAIN_ID_aggregated_beep.csv")

# data_to_write_TEST <- fix_time(data_TEST_id)
write.csv(data_TEST_id, "data/data_2_TEST_ID_aggregated_beep.csv")
```


# ---------
```{r}
data <- data_TRAIN_id
# data <- data_log_transform
```


# Imputation

## MICE

Checking NAs in all data
```{r}
for(col in colnames(data)){
  print(sum(is.na(data[[col]])))
}
```


```{r}
data <- data %>% mutate(
  was_na_mood = as.numeric(is.na(mood)),
  was_na_arousal = as.numeric(is.na(arousal)),
  was_na_valence = as.numeric(is.na(valence)),
  was_na_activity = as.numeric(is.na(activity)),
  was_na_night_activity = as.numeric(is.na(night_physical_activity))
)
```


```{r}
# x <- data
# devtools::install_github(repo = "amices/mice")

impmethod <- character(ncol(data))
names(impmethod) <- colnames(data)
impmethod["valence"] <- "pmm"
pm <- mice::make.predictorMatrix(data)
pm["valence", c(
  "ID", "observation_day", "beepo", 
  "arousal", "mood", 
  "activity", "night_physical_activity")] <- c(
    -2, -2, -2, 
    0, 0, 
    0, 0)
# run multiple imputations
res.mice.md <- mice(
  data, 
  predictorMatrix = pm,
  method=impmethod, 
  maxit=10)
data <- mice::complete(res.mice.md)




impmethod <- character(ncol(data))
names(impmethod) <- colnames(data)
impmethod["arousal"] <- "pmm"
pm <- mice::make.predictorMatrix(data)
pm["arousal", c(
  "ID", "observation_day", "beepo", 
  "mood", 
  "activity", "night_physical_activity")] <- c(
    -2, -2, -2, 
    0, 
    0, 0)
# run multiple imputations
res.mice.md <- mice(
  data, 
  predictorMatrix = pm,
  method=impmethod, 
  maxit=10)
data <- mice::complete(res.mice.md)




impmethod <- character(ncol(data))
names(impmethod) <- colnames(data)
impmethod["activity"] <- "pmm"
pm <- mice::make.predictorMatrix(data)
pm["activity", c(
  "ID", "observation_day", "beepo", 
  "mood", 
  "night_physical_activity")] <- c(
    -2, -2, -2, 
    0, 
    0)
# run multiple imputations
res.mice.md <- mice(
  data, 
  predictorMatrix = pm,
  method=impmethod, 
  maxit=10)
data <- mice::complete(res.mice.md)



impmethod <- character(ncol(data))
names(impmethod) <- colnames(data)
impmethod["night_physical_activity"] <- "pmm"
pm <- mice::make.predictorMatrix(data)
pm["night_physical_activity", c(
  "ID", "observation_day", "beepo", 
  "mood")] <- c(
    -2, -2, -2, 
    0)
# run multiple imputations
res.mice.md <- mice(
  data, 
  predictorMatrix = pm,
  method=impmethod, 
  maxit=10)
data <- mice::complete(res.mice.md)





impmethod <- character(ncol(data))
names(impmethod) <- colnames(data)
impmethod["mood"] <- "pmm"
pm <- mice::make.predictorMatrix(data)
pm["mood", c(
  "ID", "observation_day", "beepo")] <- c(
    -2, -2, -2)
# run multiple imputations
res.mice.md <- mice(
  data, 
  predictorMatrix = pm,
  method=impmethod, 
  maxit=10)
data <- mice::complete(res.mice.md)
```

```{r}
imputed_data <- data
```


```{r}
write.csv(imputed_data,"data/data_3_imputed_aggregated_beeps_ALL.csv")
```


## Kalman
```{r}
imputed <- imputeTS::na_kalman(aggregated_data)
```

```{r}
write.csv(imputed, "data_3_imputed_kalman.csv")
```



# Normalization

```{r}
data_normal <- imputed %>%
  mutate_at(vars(arousal:appCat.weather), scale)
```




# ---------

# Aggregate by Day
```{r}
aggregate_data_by_day <- imputed_data %>%
  group_by(ID, date) %>%
  summarise(
    observation_day = max(observation_day),
    mood = mean(mood, na.rm = TRUE),
    arousal = mean(arousal, na.rm = TRUE),
    valence = mean(valence, na.rm = TRUE),
    activity = mean(activity, na.rm = TRUE),
    screen = sum(screen, na.rm = TRUE),
    call = sum(call, na.rm = TRUE),
    sms = sum(sms, na.rm = TRUE),
    appCat.builtin = sum(appCat.builtin, na.rm = TRUE),
    appCat.communication = sum(appCat.communication, na.rm = TRUE),
    appCat.entertainment = sum(appCat.entertainment, na.rm = TRUE),
    appCat.finance = sum(appCat.finance, na.rm = TRUE),
    appCat.game = sum(appCat.game, na.rm = TRUE),
    appCat.office = sum(appCat.office, na.rm = TRUE),
    appCat.other = sum(appCat.other, na.rm = TRUE),
    appCat.social = sum(appCat.social, na.rm = TRUE),
    appCat.travel = sum(appCat.travel, na.rm = TRUE),
    appCat.unknown = sum(appCat.unknown, na.rm = TRUE),
    appCat.utilities = sum(appCat.utilities, na.rm = TRUE), 
    appCat.weather = sum(appCat.weather, na.rm = TRUE), 
    night_physical_activity = mean(night_physical_activity),
    night_screen = mean(night_screen),
    night_appcat_combined = mean(night_appcat_combined),
    MAX_inactivity_timediff = mean(MAX_inactivity_timediff),
    SUM_inactivity_timediff = mean(SUM_inactivity_timediff),
    weekday = max(weekday),
    week_of_year = max(week_of_year),
    appCat_total = sum(
      appCat.builtin,
      appCat.communication,
      appCat.entertainment,
      appCat.finance,
      appCat.game,
      appCat.office,
      appCat.other,
      appCat.social,
      appCat.travel,
      appCat.unknown,
      appCat.utilities,
      appCat.weather),
    was_na_mood = sum(was_na_mood),
    was_na_arousal = sum(was_na_arousal),
    was_na_valence = sum(was_na_valence),
    was_na_activity = sum(was_na_activity),
    was_na_night_activity = sum(was_na_night_activity),
    across(starts_with("binary_"), ~ sum(.x, na.rm = TRUE)),
    .groups = "drop")

# colnames(aggregate_data_by_day)[1] = "id"
# colnames(aggregate_data_by_day)[2] = "datetime"
```

```{r}
# Calculating the Daily Average Mood
aggregate_data_by_day <- aggregate_data_by_day %>%
  group_by(ID) %>% mutate(mood_of_next_day = lead(mood))
```


```{r}
library(zoo)

# Assuming `data` is your dataframe, `date` is the column with date information,
# `participant_id` is the column that identifies individual participants, and
# `mood` is the column for which you want to calculate rolling averages.
aggregate_data_by_day$ID
# Make sure your data is sorted by participant and date
aggregate_data_by_day <- aggregate_data_by_day[
  order(aggregate_data_by_day$ID, aggregate_data_by_day$observation_day), ]

# Calculate rolling averages for each participant
aggregate_data_by_day$roll_mean_3 <- NA  # Initialize the column with NA values
aggregate_data_by_day$roll_mean_7 <- NA  # Initialize the column with NA values

unique_ids <- unique(aggregate_data_by_day$ID)

for(id in unique_ids){
  participant_data <- subset(aggregate_data_by_day, ID == id)
  
  # Calculate 3-day rolling average
  # The align="right" parameter ensures that the rolling window includes the current day and the previous 2 days
  roll_3 <- rollapply(participant_data$mood, width = 3, FUN = mean, align = "right", fill = NA)
  
  # Calculate 7-day rolling average
  roll_7 <- rollapply(participant_data$mood, width = 7, FUN = mean, align = "right", fill = NA)
  
  # Assign the calculated values back to the appropriate rows in the original dataframe
  aggregate_data_by_day$roll_mean_3[aggregate_data_by_day$ID == id] <- roll_3
  aggregate_data_by_day$roll_mean_7[aggregate_data_by_day$ID == id] <- roll_7
}

# `data` now includes the rolling average columns: `roll_mean_3` and `roll_mean_7`

```



```{r}
write.csv(aggregate_data_by_day,"data/data_4_aggregated_day_ALL.csv")
```


# Creating Mood Lags

```{r}
beep_new <- imputed_data
```


DAY:
```{r}
# Calculating the Daily Average Mood
daily_moods <- beep_new %>%
  group_by(ID, observation_day) %>%
  summarise(daily_average_mood = mean(mood, na.rm = TRUE), .groups = 'drop')

# Join the daily averages back to the original data 
# and then calculate the average mood for the next day
beep_new <- beep_new %>%
  left_join(daily_moods, by = c("ID", "observation_day")) %>% 
  group_by(ID) %>% 
  mutate(mood_of_yesterday = lag(daily_average_mood, n=5)) %>%
  ungroup()
```

BEEP:
```{r}
beep_new <- beep_new %>% 
  group_by(ID) %>% 
  mutate(
    mood_of_next_beep = lead(mood)
)
```

```{r}

# Assuming `data` is your dataframe, `date` is the column with date information,
# `participant_id` is the column that identifies individual participants, and
# `mood` is the column for which you want to calculate rolling averages.

# Make sure your data is sorted by participant and date
beep_new <- beep_new[
  order(beep_new$ID, beep_new$observation_day, beep_new$beepo), ]

# Calculate rolling averages for each participant
beep_new$roll_mean_15 <- NA
beep_new$roll_mean_45 <- NA  # Initialize the column with NA values


unique_ids <- unique(beep_new$ID)

for(id in unique_ids){
  participant_data <- subset(beep_new, ID == id)
  
  # Calculate 3-day rolling average
  # The align="right" parameter ensures that the rolling window includes the current day and the previous 2 days
  #roll_3 <- rollapply(participant_data$mood, width = 3, FUN = mean, align = "right", fill = NA)
  
  # Calculate 7-day rolling average
  roll_7 <- rollapply(participant_data$mood, width = 15, FUN = mean, align = "right", fill = NA)
  
  roll_15 <- rollapply(participant_data$mood, width = 45, FUN = mean, align = "right", fill = NA)
  
  # Assign the calculated values back to the appropriate rows in the original dataframe
  #beep_new$roll_mean_3[beep_new$ID == id] <- roll_3
  beep_new$roll_mean_15[beep_new$ID == id] <- roll_7
  beep_new$roll_mean_45[beep_new$ID == id] <- roll_15
}

```


```{r}
beep_new <- beep_new %>%
  group_by(ID) %>%
  mutate(median_mood = median(mood, na.rm = TRUE)) %>%
  ungroup()

# Step 2: Create a new variable to categorize mood based on the median
beep_new <- beep_new %>%
  mutate(mood_category = case_when(
    mood < median_mood ~ -1,
    mood == median_mood ~ 0,
    mood > median_mood ~ 1
  ))

```

```{r}
beep_new <- beep_new %>% 
  group_by(ID) %>% 
  mutate(
    mood_of_next_beep = lead(mood_category)
)
```


```{r}

# Assuming beep_new is your dataset
variables <- names(data)

# Exclude the dependent variable and random effects identifiers
fixed_effects <- variables[!variables %in% c("mood", "ID", "observation_day", "beepo")]

# Create the fixed effects part of the formula by collapsing the variable names into a formula string
fixed_effects_formula <- paste(fixed_effects, collapse = " + ")

# Create the full model formula
model_formula <- as.formula(paste("mood ~", fixed_effects_formula, 
                                  "+ (1|ID) + (1|ID:observation_day) + (1|beepo)"))

# Fit the model
full_model <- lmer(model_formula, data = data)
library(performance)

performance::r2(full_model)

# Check the model summary
library(lme4)
library(lmerTest)  # for model comparison if needed later

# Assuming your full model is properly specified and saved as `current_model`
current_model <- lmer(mood ~ . + (1|ID) + (1|ID:observation_day) + (1|beepo), data = beep_new)
best_aic <- AIC(current_model)
current_formula <- formula(current_model)  # Get the model's formula

# Iterate over all variables except the specified ones
for (variable in setdiff(names(beep_new), c("mood", "ID", "observation_day", "beepo"))) {
    # Create a new formula by dropping the variable
    new_formula <- as.formula(paste(deparse(current_formula), "- ", variable))
    
    # Fit the new model with the updated formula
    reduced_model <- try(lmer(new_formula, data = beep_new), silent = TRUE)
    
    # Check if the new model fit without error and calculate AIC
    if (!inherits(reduced_model, "try-error")) {
        model_aic <- AIC(reduced_model)
        if (model_aic < best_aic) {
            best_aic <- model_aic
            current_model <- reduced_model
            current_formula <- new_formula  # Update the formula to the new best model
            cat("Dropped:", variable, "New AIC:", model_aic, "\n")
        }
    }
}

# Final model after dropping variables
summary(current_model)

```



```{r}
write.csv(beep_new, "data/data_4_imputed_aggregated_beep_ALL.csv")
```


```{r}
write.csv(beep_new, "data/xxxxxxxx.csv")
```



Then aggregating the dataset based on beeps.
```{r}
# Example aggregation: Calculate the mean mood for each beep interval for each participant
# You can change this to match the specific columns and summary statistics you need
aggregated_data <- combined_data %>%
  group_by(ID, beep_number) %>%
  summarize(mean_mood = mean(mood, na.rm = TRUE), .groups = 'drop')

```







