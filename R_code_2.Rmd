---
title: "Mood"
author: "Arda Ergin"
date: "2024-04-02"
output: html_document
---

# Adding Beeps

First assigning new rows with beeps to the dataset.
```{r}
# Generate additional times and beeps
additional_times <- c(
  "06:00:01", # ghost beep to mark night time
  "09:00:01", 
  "12:00:01", 
  "15:00:01", 
  "18:00:01", 
  "21:00:01")
beep_identifiers <- c(0, 1, 2, 3, 4, 5) 
dates <- unique(as.Date(data$date_time))
participants <- unique(data$ID)

# Map times to beep identifiers
time_to_beep <- setNames(beep_identifiers, additional_times)
# Create a data frame of all combinations of dates, times, and participants
expanded_data <- expand.grid(
  date = dates, 
  time = additional_times, 
  ID = participants)
expanded_data$date_time <- as.POSIXct(paste(
  expanded_data$date, 
  expanded_data$time))
expanded_data$beep_number <- time_to_beep[as.character(expanded_data$time)]

# Initialize columns for expanded_data that are in data but not in expanded_data
additional_columns <- setdiff(names(data), names(expanded_data))
for (col in additional_columns) {
  expanded_data[[col]] <- NA
}

# Combine original and expanded data
data$beep_number <- NA # since this variable does not exist in the original dataset
combined_data <- rbind(data, expanded_data)

# Remove duplicate rows and sort by date_time
combined_data <- combined_data %>%
  arrange(ID, date_time) %>%
  distinct()

# Make sure it is sorted by ID and date_time
combined_data <- combined_data %>%
  arrange(ID, date_time)

# Fill beep_number NA values using zoo::na.locf()
combined_data$beepo <- zoo::na.locf(
  combined_data$beep_number, 
  na.rm = FALSE, 
  fromLast = TRUE)

### THE OTHER WAY:: ###
#combined_data$beepo2 <- zoo::na.locf(
#  combined_data$beep_number, 
#  na.rm = FALSE)
```


```{r}
combined_data_clean <- clean_id_time(combined_data)
```


```{r}
# Create a flag that identifies each transition from beep 5 to beep 0
combined_data_clean <- combined_data_clean %>%
  group_by(ID) %>% mutate(
    new_day_flag = if_else(lag(beepo, default = first(beepo)) == 5 & beepo == 0, 1, 0),
    # Cumulatively sum these flags to identify unique observation days for each participant
    observation_day = cumsum(new_day_flag)) %>%
  ungroup()
```


```{r}
combined_data_clean_removed_obs_day_0 <- combined_data_clean %>% 
  filter(observation_day != 0) %>% subset(select = -new_day_flag)
```

```{r}
data <- combined_data_clean_removed_obs_day_0
# x <- data
```

# --------------------


# Sleep

```{r}
data_beepo_0 <- combined_data_clean_removed_obs_day_0 %>% filter(
  beepo == 0 | (time == "21:00:01" & is.na(obs_number)))
```


```{r}
# Sort data by date_time
data_beepo_0 <- data_beepo_0 %>% arrange(ID, date_time)
```


## Potential Sleep Gap
```{r}
# Column for the time difference between 
# the current observation and the last observation
data_beepo_0 <- data_beepo_0 %>% 
  group_by(ID, observation_day) %>% mutate(
  # For every observation, getting the difference between the previous
  time_diff = round(
    difftime(date_time, lag(date_time),
             units = "hours"), 3),
  # If it is 15, then make it 9, for looking at sleep later
  time_diff_adj = ifelse(time_diff == 15, 0, time_diff),
  # Gap based on both these variables
  possible_sleep_gap = (time_diff_adj > 1 & time_diff_adj <= 9),
  time_diff_valid = ifelse(
    possible_sleep_gap, time_diff_adj, 0)
  ) %>% 
  ungroup()
```

## Inactivity

```{r}
# Inactivity
data_beepo_0 <- data_beepo_0 %>% mutate(
  is_inactive = dplyr::case_when(
    is.na(activity) ~ FALSE,
    activity == 0 ~ TRUE,
    TRUE ~ FALSE))

# Applying a run-length encoding to count consecutive inactive periods
data_beepo_0 <- data_beepo_0 %>% group_by(ID) %>% mutate(
    consecutive_inactive = with(rle(is_inactive), {
      # Only count lengths where is_inactive is TRUE:
      lengths_corrected <- lengths * values  
      # Repeat these lengths according to run lengths:
      rep(lengths_corrected, lengths)   
    })) %>% 
  ungroup()

# Getting rid of the consequitve duplicates so that summing up later is easier.
data_beepo_0 <- data_beepo_0 %>%
  mutate(
    # Use lag to compare each value to the previous, 
    # initializing the first comparison to TRUE
    consecutive_inactive_fix = if_else(
      consecutive_inactive != lead(
        consecutive_inactive, 
        default = consecutive_inactive[n()]+1), 
      (consecutive_inactive - 1), 0),
    
    consecutive_inactive_fix = if_else(
      consecutive_inactive_fix == -1,
      0,
      consecutive_inactive_fix)
  )

table(data_beepo_0$consecutive_inactive_fix)
```

```{r}
aggregated_night_data <- data_beepo_0 %>%
  group_by(ID, observation_day) %>%
  summarise(
    night_mood = safe_mean(mood),
    night_arousal = safe_mean(circumplex.arousal),
    night_valence = safe_mean(circumplex.valence),
    
    night_physical_activity = safe_mean(activity),
    
    night_screen = sum(screen, na.rm = T),
    
    night_appcat_combined = sum(
      appCat.builtin,
      appCat.communication,
      appCat.entertainment,
      appCat.finance,
      appCat.game,
      appCat.office,
      appCat.other,
      appCat.social,
      appCat.travel,
      appCat.unknown,
      appCat.utilities,
      appCat.weather, na.rm = T),
    
    total_time_diff = safe_sum(time_diff_valid),
    max_time_diff = max(time_diff_valid, na.rm = T),
    
    total_inactivity = safe_sum(consecutive_inactive_fix),
    max_inactivity = max(consecutive_inactive_fix, na.rm = T),
    
    SUM_inactivity_timediff = sum(
      total_inactivity, 
      total_time_diff, 
      na.rm = T),
    
    MAX_inactivity_timediff = max(
      max_time_diff, 
      max_inactivity, 
      na.rm = T),
    .groups = "drop")
```


# Aggregating Data

```{r}
aggregated_data <- combined_data_clean_removed_obs_day_0 %>%
  group_by(ID, observation_day, beepo) %>%
  summarise(
    date = max(date),
    mood = mean(mood, na.rm = TRUE),
    arousal = mean(circumplex.arousal, na.rm = TRUE),
    valence = mean(circumplex.valence, na.rm = TRUE),
    activity = mean(activity, na.rm = TRUE),
    screen = sum(screen, na.rm = TRUE),
    call = sum(call, na.rm = TRUE),
    sms = sum(sms, na.rm = TRUE),
    appCat.builtin = sum(appCat.builtin, na.rm = TRUE),
    appCat.communication = sum(appCat.communication, na.rm = TRUE),
    appCat.entertainment = sum(appCat.entertainment, na.rm = TRUE),
    appCat.finance = sum(appCat.finance, na.rm = TRUE),
    appCat.game = sum(appCat.game, na.rm = TRUE),
    appCat.office = sum(appCat.office, na.rm = TRUE),
    appCat.other = sum(appCat.other, na.rm = TRUE),
    appCat.social = sum(appCat.social, na.rm = TRUE),
    appCat.travel = sum(appCat.travel, na.rm = TRUE),
    appCat.unknown = sum(appCat.unknown, na.rm = TRUE),
    appCat.utilities = sum(appCat.utilities, na.rm = TRUE), 
    appCat.weather = sum(appCat.weather, na.rm = TRUE), 
    .groups = "drop")
```


```{r}
data_with_night <- aggregated_data %>%
  left_join(aggregated_night_data, by = c("ID", "observation_day")) %>% 
  filter(beepo != 0)
```

NIGHT MOOD REPLACING
```{r}
data_with_night <- data_with_night %>%
  arrange(ID, observation_day, beepo) %>%
  group_by(ID) %>% mutate(
    # Create lagged versions of night variables to fill backwards
    lead_night_mood = if_else(
      beepo == 5, 
      lead(night_mood, default = first(night_mood)), 
      NA_real_),
    
    lead_night_arousal = if_else(
      beepo == 5, 
      lead(night_arousal, default = first(night_arousal)),
      NA_real_),
    
    lead_night_valence = if_else(
      beepo == 5, 
      lead(night_valence, default = first(night_valence)), 
      NA_real_)) %>% ungroup()

data_with_night <- data_with_night %>% mutate(
    mood = case_when(
      beepo == 5 & is.na(mood) ~ lead_night_mood,
      beepo == 5 & !is.na(mood) & !is.na(lead_night_mood) ~ 
        (mood + lead_night_mood)/2,
      TRUE ~ mood
    ),
    arousal = case_when(
      beepo == 5 & is.na(arousal) ~ lead_night_arousal,
      beepo == 5 & !is.na(arousal) & !is.na(lead_night_arousal) ~ 
        (arousal + lead_night_arousal)/2,
      TRUE ~ arousal
    ),
    valence = case_when(
      beepo == 5 & is.na(valence) ~ lead_night_valence,
      beepo == 5 & !is.na(valence) & !is.na(lead_night_valence) ~ 
        (valence + lead_night_valence)/2,
      TRUE ~ valence)
    )
```


```{r}
data <- data_with_night
```


choosing night variables and some cleaning 
```{r}
data <- data %>% subset(
  select = -c(night_mood, night_arousal, night_valence,
              total_time_diff, max_time_diff, 
              total_inactivity, max_inactivity, 
              lead_night_mood, lead_night_arousal, lead_night_valence))

# Creating Variable: the day of the week (of Observation)
data <- data %>%
  mutate(weekday = weekdays(date),
         weekday = as.numeric(factor(
           weekday,
           labels = 1:7,
           levels = c("Monday", "Tuesday", 
                      "Wednesday", "Thursday", 
                      "Friday", "Saturday", 
                      "Sunday"))))

# Creating Variable: the week of the year (of Observation)
data <- data %>%
  mutate(week_of_year = lubridate::week(date))
```


# ---------------

# Outliers and Log Transform
```{r}
for (i in names(data)) {
  if (is.numeric(data[[i]])) {
    boxplot(data[[i]], main = i)
  }
}

```


```{r}
mood_summary %>% ggplot(aes(x = "", y = sd_mood)) +
  geom_boxplot(color = "firebrick") +
  theme_classic(base_family = "Times") +
  labs(title = "Boxplot of Standard Deviation of Mood",
       y = "Standard Deviation of Mood",
       x = "")
```



```{r}
for (i in names(data)) {
  if (is.numeric(data[[i]])) {
    hist(data[[i]], main = i)
    hist(log1p(data[[i]]), main = i)
  }
}
```



```{r}
data_log_transform <- data

# Columns to log-transform
columns_to_log_transform <- c(
  # "activity", "night_physical_activity",
  "screen", "appCat.builtin", "appCat.communication",
  "appCat.entertainment", "appCat.finance", "appCat.game",
  "appCat.office", "appCat.other", "appCat.social",
  "appCat.travel", "appCat.unknown", "appCat.utilities", 
  "appCat.weather", 
  "night_screen", 
  "night_appcat_combined")

# 
for (col in columns_to_log_transform) {
  data_log_transform[[paste0("binary_", col)]] <- as.integer(data_log_transform[[col]] > 0)
}

# Apply log transformation to selected columns
# log1p for handling zero by adding 1
data_log_transform[columns_to_log_transform] <-
  lapply(data_log_transform[columns_to_log_transform], log1p)
```


```{r}
columns_to_log_transform <- c(
  # "activity", "night_physical_activity",
  "screen", "appCat.builtin", "appCat.communication",
  "appCat.entertainment", "appCat.finance", "appCat.game",
  "appCat.office", "appCat.other", "appCat.social",
  "appCat.travel", "appCat.unknown", "appCat.utilities", 
  "appCat.weather", 
  "night_screen", 
  "night_appcat_combined"
)

# Log-transform and create binary indicator
data_log_transform <- data_log_transform %>%
  mutate(across(all_of(columns_to_log_transform), ~log1p(.), .names = "log_{.col}")) %>%
  mutate(across(all_of(columns_to_log_transform), ~as.integer(. > 0), .names = "binary_{.col}"))

# Normalize the log-transformed variables, replace 0 with NA, and impute NAs with the mean
data_log_transform <- data_log_transform %>%
  mutate(across(starts_with("log_"), ~{
    # Replace 0 with NA
    .x <- ifelse(.x == 0, NA, .x)
    # Calculate mean without NA
    mean_val <- mean(.x, na.rm = TRUE)
    # Normalize non-NA values
    .x <- ifelse(!is.na(.x), (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE), .x)
    # Replace NA with mean
    .x <- ifelse(is.na(.x), mean_val, .x)
  }))


```


```{r}
# Specifying the columns to transform
columns_to_log_transform <- c(
  # "activity", "night_physical_activity",
  "screen", "appCat.builtin", "appCat.communication",
  "appCat.entertainment", "appCat.finance", "appCat.game",
  "appCat.office", "appCat.other", "appCat.social",
  "appCat.travel", "appCat.unknown", "appCat.utilities", 
  "appCat.weather", 
  "night_screen", 
  "night_appcat_combined"
)

# Step 1: Log-transform the specified columns
for (col in columns_to_log_transform) {
  # Apply log1p transformation
  data_log_transform[[paste0("log_", col)]] <- log1p(data_log_transform[[col]])
}

# Step 2: Create binary indicators for the specified columns

```

```{r}

# Step 3: Normalize log-transformed variables and handle zeros
for (col in columns_to_log_transform) {
  log_col <- paste0("log_", col)
  
  # Replace 0 with NA for log-transformed column
  data_log_transform[[log_col]][data_log_transform[[log_col]] == 0] <- NA
  
  # Calculate mean of the log-transformed column, excluding NA
  mean_val <- mean(data_log_transform[[log_col]], na.rm = TRUE)
  
  # Calculate standard deviation of the log-transformed column, excluding NA
  sd_val <- sd(data_log_transform[[log_col]], na.rm = TRUE)
  
  # Normalize the log-transformed column, excluding NA
  data_log_transform[[log_col]] <- ifelse(
    !is.na(data_log_transform[[log_col]]),
    (data_log_transform[[log_col]] - mean_val) / sd_val,
    data_log_transform[[log_col]]
  )
  
  # Replace NA with mean of the normalized log-transformed values
  data_log_transform[[log_col]][is.na(data_log_transform[[log_col]])] <- 0
}
for (i in names(data_log_transform)) {
  if (is.numeric(data_log_transform[[i]])) {
    hist(data_log_transform[[i]], main = i)
  }
}X
```




```{r}
library(glmmTMB)
data_log_transform$SUM_inactivity_timediff
# Let's say you have a random effect 'random_effect_var' which is a grouping factor like a subject ID or a site ID.
zip_mixed_model <- glmmTMB::glmmTMB(
  mood ~ arousal + valence + 
    appCat.builtin + appCat.communication + appCat.entertainment + 
    week_of_year + weekday + SUM_inactivity_timediff + (1 | ID), 
  zi=~ appCat.builtin + appCat.communication + appCat.entertainment, 
  data = data_log_transform, 
    family = nbinom1)

```



```{r}
data_normal <- data %>%
  mutate_at(vars(activity:night_appcat_combined), scale)
```


```{r}
# Fitting a linear model with the same fixed effects
lm_model <- lm(mood ~ arousal + valence + activity + screen + call + sms +
               appCat.builtin + appCat.communication + appCat.entertainment +
               appCat.finance + appCat.game + appCat.office + appCat.other +
               appCat.social + appCat.travel + appCat.unknown + appCat.utilities +
               appCat.weather + night_physical_activity + night_screen +
               night_appcat_combined + SUM_inactivity_timediff + weekday +
               week_of_year, data = data)

# Calculating VIF for the linear model
car::vif(lm_model)

```


```{r}
data$week_of_year
model <- lme4::lmer(
  mood ~ 
    arousal + valence +
    activity + screen + 
    call + sms + 
    appCat.builtin + appCat.communication + 
    appCat.entertainment + appCat.finance + 
    appCat.game + appCat.office + appCat.other + 
    appCat.social + appCat.travel + appCat.unknown + 
    appCat.utilities + appCat.weather + night_physical_activity + 
    night_screen + night_appcat_combined + SUM_inactivity_timediff + 
    weekday + week_of_year + 
    (1|ID/observation_day), 
  data=data)
summary(model)
car::vif(model)

model <- lmerTest::lmer(mood ~ 
    arousal + valence +
    activity + screen + 
    call + sms + 
    appCat.builtin + appCat.communication + 
    appCat.entertainment + appCat.finance + 
    appCat.game + appCat.office + appCat.other + 
    appCat.social + appCat.travel + appCat.unknown + 
    appCat.utilities + appCat.weather + night_physical_activity + 
    night_screen + night_appcat_combined + SUM_inactivity_timediff + 
    weekday + week_of_year + 
    (1|ID/observation_day), 
  data=data)
```








# ---------



# Train-test Split

## Time
Based on time
```{r}
test_days <- length(unique(data$date)) * (1/5)

data_TRAIN_time <- data %>% filter(date <= max(data$date) - test_days)
length(unique(data_TRAIN_time$date))


data_TEST_time <- data %>% filter(date > max(data$date) - test_days)
length(unique(data_TEST_time$date))
```

## EXPORT DATA_2 - TIME
```{r}
data_to_write_TRAIN <- fix_time(data_TRAIN_time)
write.csv(data_to_write_TRAIN, "data/data_2_TRAIN_TIME_not_aggregated.csv")

data_to_write_TEST <- fix_time(data_TEST_time)
write.csv(data_to_write_TEST, "data/data_2_TEST_TIME_not_aggregated.csv")
```


## Participant
Based on participant

```{r}
participants <- unique(data$ID)
set.seed(11042024) # Setting random seed with the date
test_participants <- sample(participants, length(participants)* 1/5)
test_participants

data_TEST_id <- data %>% filter(ID %in% test_participants)
unique(as.numeric(data_TEST_id$ID))

`%not_in%` <- purrr::negate(`%in%`)
data_TRAIN_id <- data %>% dplyr::filter(ID %not_in% test_participants)
unique(as.numeric(data_TRAIN_id$ID))
```

## EXPORT DATA_2 - ID
```{r}
# data_to_write_TRAIN <- fix_time(data_TRAIN_id)
write.csv(data_TRAIN_id, "data/data_2_TRAIN_ID_aggregated_beep.csv")

# data_to_write_TEST <- fix_time(data_TEST_id)
write.csv(data_TEST_id, "data/data_2_TEST_ID_aggregated_beep.csv")
```


# ---------
```{r}
data <- data_TRAIN_id
# data <- data_log_transform
```


# MICE

Checking NAs in all data
```{r}
for(col in colnames(data)){
  print(sum(is.na(data[[col]])))
}
```


```{r}
data <- data %>% mutate(
  was_na_mood = as.numeric(is.na(mood)),
  was_na_arousal = as.numeric(is.na(arousal)),
  was_na_valence = as.numeric(is.na(valence)),
  was_na_activity = as.numeric(is.na(activity)),
  was_na_night_activity = as.numeric(is.na(night_physical_activity))
)
```


```{r}
# x <- data
# devtools::install_github(repo = "amices/mice")

impmethod <- character(ncol(data))
names(impmethod) <- colnames(data)
impmethod["valence"] <- "pmm"
pm <- mice::make.predictorMatrix(data)
pm["valence", c(
  "ID", "observation_day", "beepo", 
  "arousal", "mood", 
  "activity", "night_physical_activity")] <- c(
    -2, -2, -2, 
    0, 0, 
    0, 0)
# run multiple imputations
res.mice.md <- mice(
  data, 
  predictorMatrix = pm,
  method=impmethod, 
  maxit=10)
data <- mice::complete(res.mice.md)




impmethod <- character(ncol(data))
names(impmethod) <- colnames(data)
impmethod["arousal"] <- "pmm"
pm <- mice::make.predictorMatrix(data)
pm["arousal", c(
  "ID", "observation_day", "beepo", 
  "mood", 
  "activity", "night_physical_activity")] <- c(
    -2, -2, -2, 
    0, 
    0, 0)
# run multiple imputations
res.mice.md <- mice(
  data, 
  predictorMatrix = pm,
  method=impmethod, 
  maxit=10)
data <- mice::complete(res.mice.md)




impmethod <- character(ncol(data))
names(impmethod) <- colnames(data)
impmethod["activity"] <- "pmm"
pm <- mice::make.predictorMatrix(data)
pm["activity", c(
  "ID", "observation_day", "beepo", 
  "mood", 
  "night_physical_activity")] <- c(
    -2, -2, -2, 
    0, 
    0)
# run multiple imputations
res.mice.md <- mice(
  data, 
  predictorMatrix = pm,
  method=impmethod, 
  maxit=10)
data <- mice::complete(res.mice.md)



impmethod <- character(ncol(data))
names(impmethod) <- colnames(data)
impmethod["night_physical_activity"] <- "pmm"
pm <- mice::make.predictorMatrix(data)
pm["night_physical_activity", c(
  "ID", "observation_day", "beepo", 
  "mood")] <- c(
    -2, -2, -2, 
    0)
# run multiple imputations
res.mice.md <- mice(
  data, 
  predictorMatrix = pm,
  method=impmethod, 
  maxit=10)
data <- mice::complete(res.mice.md)





impmethod <- character(ncol(data))
names(impmethod) <- colnames(data)
impmethod["mood"] <- "pmm"
pm <- mice::make.predictorMatrix(data)
pm["mood", c(
  "ID", "observation_day", "beepo")] <- c(
    -2, -2, -2)
# run multiple imputations
res.mice.md <- mice(
  data, 
  predictorMatrix = pm,
  method=impmethod, 
  maxit=10)
data <- mice::complete(res.mice.md)
```

```{r}
imputed_data <- data
```


```{r}
write.csv(imputed_data,"data/data_3_imputed_aggregated_beeps_ALL.csv")
```



# ---------

# Aggregate by Day
```{r}
aggregate_data_by_day <- imputed_data %>%
  group_by(ID, date) %>%
  summarise(
    observation_day = max(observation_day),
    mood = mean(mood, na.rm = TRUE),
    arousal = mean(arousal, na.rm = TRUE),
    valence = mean(valence, na.rm = TRUE),
    activity = mean(activity, na.rm = TRUE),
    screen = sum(screen, na.rm = TRUE),
    call = sum(call, na.rm = TRUE),
    sms = sum(sms, na.rm = TRUE),
    appCat.builtin = sum(appCat.builtin, na.rm = TRUE),
    appCat.communication = sum(appCat.communication, na.rm = TRUE),
    appCat.entertainment = sum(appCat.entertainment, na.rm = TRUE),
    appCat.finance = sum(appCat.finance, na.rm = TRUE),
    appCat.game = sum(appCat.game, na.rm = TRUE),
    appCat.office = sum(appCat.office, na.rm = TRUE),
    appCat.other = sum(appCat.other, na.rm = TRUE),
    appCat.social = sum(appCat.social, na.rm = TRUE),
    appCat.travel = sum(appCat.travel, na.rm = TRUE),
    appCat.unknown = sum(appCat.unknown, na.rm = TRUE),
    appCat.utilities = sum(appCat.utilities, na.rm = TRUE), 
    appCat.weather = sum(appCat.weather, na.rm = TRUE), 
    night_physical_activity = mean(night_physical_activity),
    night_screen = mean(night_screen),
    night_appcat_combined = mean(night_appcat_combined),
    MAX_inactivity_timediff = mean(MAX_inactivity_timediff),
    SUM_inactivity_timediff = mean(SUM_inactivity_timediff),
    weekday = max(weekday),
    week_of_year = max(week_of_year),
    appCat_total = sum(
      appCat.builtin,
      appCat.communication,
      appCat.entertainment,
      appCat.finance,
      appCat.game,
      appCat.office,
      appCat.other,
      appCat.social,
      appCat.travel,
      appCat.unknown,
      appCat.utilities,
      appCat.weather),
    was_na_mood = sum(was_na_mood),
    was_na_arousal = sum(was_na_arousal),
    was_na_valence = sum(was_na_valence),
    was_na_activity = sum(was_na_activity),
    was_na_night_activity = sum(was_na_night_activity),
    across(starts_with("binary_"), ~ sum(.x, na.rm = TRUE)),
    .groups = "drop")

# colnames(aggregate_data_by_day)[1] = "id"
# colnames(aggregate_data_by_day)[2] = "datetime"
```

```{r}
# Calculating the Daily Average Mood
aggregate_data_by_day <- aggregate_data_by_day %>%
  group_by(ID) %>% mutate(mood_of_next_day = lead(mood))
```


```{r}
library(zoo)

# Assuming `data` is your dataframe, `date` is the column with date information,
# `participant_id` is the column that identifies individual participants, and
# `mood` is the column for which you want to calculate rolling averages.
aggregate_data_by_day$ID
# Make sure your data is sorted by participant and date
aggregate_data_by_day <- aggregate_data_by_day[
  order(aggregate_data_by_day$ID, aggregate_data_by_day$observation_day), ]

# Calculate rolling averages for each participant
aggregate_data_by_day$roll_mean_3 <- NA  # Initialize the column with NA values
aggregate_data_by_day$roll_mean_7 <- NA  # Initialize the column with NA values

unique_ids <- unique(aggregate_data_by_day$ID)

for(id in unique_ids){
  participant_data <- subset(aggregate_data_by_day, ID == id)
  
  # Calculate 3-day rolling average
  # The align="right" parameter ensures that the rolling window includes the current day and the previous 2 days
  roll_3 <- rollapply(participant_data$mood, width = 3, FUN = mean, align = "right", fill = NA)
  
  # Calculate 7-day rolling average
  roll_7 <- rollapply(participant_data$mood, width = 7, FUN = mean, align = "right", fill = NA)
  
  # Assign the calculated values back to the appropriate rows in the original dataframe
  aggregate_data_by_day$roll_mean_3[aggregate_data_by_day$ID == id] <- roll_3
  aggregate_data_by_day$roll_mean_7[aggregate_data_by_day$ID == id] <- roll_7
}

# `data` now includes the rolling average columns: `roll_mean_3` and `roll_mean_7`

```



```{r}
write.csv(aggregate_data_by_day,"data/data_4_aggregated_day_ALL.csv")
```


# Creating Mood Lags

```{r}
beep_new <- imputed_data
```


DAY:
```{r}
# Calculating the Daily Average Mood
daily_moods <- beep_new %>%
  group_by(ID, observation_day) %>%
  summarise(daily_average_mood = mean(mood, na.rm = TRUE), .groups = 'drop')

# Join the daily averages back to the original data 
# and then calculate the average mood for the next day
beep_new <- beep_new %>%
  left_join(daily_moods, by = c("ID", "observation_day")) %>% 
  group_by(ID) %>% 
  mutate(mood_of_yesterday = lag(daily_average_mood, n=5)) %>%
  ungroup()
```

BEEP:
```{r}
beep_new <- beep_new %>% 
  group_by(ID) %>% 
  mutate(
    mood_of_next_beep = lead(mood)
)
```

```{r}

# Assuming `data` is your dataframe, `date` is the column with date information,
# `participant_id` is the column that identifies individual participants, and
# `mood` is the column for which you want to calculate rolling averages.

# Make sure your data is sorted by participant and date
beep_new <- beep_new[
  order(beep_new$ID, beep_new$observation_day, beep_new$beepo), ]

# Calculate rolling averages for each participant
beep_new$roll_mean_15 <- NA
beep_new$roll_mean_45 <- NA  # Initialize the column with NA values


unique_ids <- unique(beep_new$ID)

for(id in unique_ids){
  participant_data <- subset(beep_new, ID == id)
  
  # Calculate 3-day rolling average
  # The align="right" parameter ensures that the rolling window includes the current day and the previous 2 days
  #roll_3 <- rollapply(participant_data$mood, width = 3, FUN = mean, align = "right", fill = NA)
  
  # Calculate 7-day rolling average
  roll_7 <- rollapply(participant_data$mood, width = 15, FUN = mean, align = "right", fill = NA)
  
  roll_15 <- rollapply(participant_data$mood, width = 45, FUN = mean, align = "right", fill = NA)
  
  # Assign the calculated values back to the appropriate rows in the original dataframe
  #beep_new$roll_mean_3[beep_new$ID == id] <- roll_3
  beep_new$roll_mean_15[beep_new$ID == id] <- roll_7
  beep_new$roll_mean_45[beep_new$ID == id] <- roll_15
}

```


```{r}
beep_new <- beep_new %>%
  group_by(ID) %>%
  mutate(median_mood = median(mood, na.rm = TRUE)) %>%
  ungroup()

# Step 2: Create a new variable to categorize mood based on the median
beep_new <- beep_new %>%
  mutate(mood_category = case_when(
    mood < median_mood ~ -1,
    mood == median_mood ~ 0,
    mood > median_mood ~ 1
  ))

```

```{r}
beep_new <- beep_new %>% 
  group_by(ID) %>% 
  mutate(
    mood_of_next_beep = lead(mood_category)
)
```


```{r}
library(lme4)

# Assuming beep_new is your dataset
variables <- names(beep_new)

# Exclude the dependent variable and random effects identifiers
fixed_effects <- variables[!variables %in% c("mood", "ID", "observation_day", "beepo")]

# Create the fixed effects part of the formula by collapsing the variable names into a formula string
fixed_effects_formula <- paste(fixed_effects, collapse = " + ")

# Create the full model formula
model_formula <- as.formula(paste("mood ~", fixed_effects_formula, 
                                  "+ (1|ID) + (1|ID:observation_day) + (1|beepo)"))

# Fit the model
full_model <- lmer(model_formula, data = beep_new)

# Check the model summary
library(lme4)
library(lmerTest)  # for model comparison if needed later

# Assuming your full model is properly specified and saved as `current_model`
current_model <- lmer(mood ~ . + (1|ID) + (1|ID:observation_day) + (1|beepo), data = beep_new)
best_aic <- AIC(current_model)
current_formula <- formula(current_model)  # Get the model's formula

# Iterate over all variables except the specified ones
for (variable in setdiff(names(beep_new), c("mood", "ID", "observation_day", "beepo"))) {
    # Create a new formula by dropping the variable
    new_formula <- as.formula(paste(deparse(current_formula), "- ", variable))
    
    # Fit the new model with the updated formula
    reduced_model <- try(lmer(new_formula, data = beep_new), silent = TRUE)
    
    # Check if the new model fit without error and calculate AIC
    if (!inherits(reduced_model, "try-error")) {
        model_aic <- AIC(reduced_model)
        if (model_aic < best_aic) {
            best_aic <- model_aic
            current_model <- reduced_model
            current_formula <- new_formula  # Update the formula to the new best model
            cat("Dropped:", variable, "New AIC:", model_aic, "\n")
        }
    }
}

# Final model after dropping variables
summary(current_model)

```



```{r}
write.csv(beep_new, "data/data_4_imputed_aggregated_beep_ALL.csv")
```


```{r}
write.csv(beep_new, "data/xxxxxxxx.csv")
```
















Then aggregating the dataset based on beeps.
```{r}
# Example aggregation: Calculate the mean mood for each beep interval for each participant
# You can change this to match the specific columns and summary statistics you need
aggregated_data <- combined_data %>%
  group_by(ID, beep_number) %>%
  summarize(mean_mood = mean(mood, na.rm = TRUE), .groups = 'drop')

```








# Imputation
## Kalman
```{r}
imputed <- imputeTS::na_kalman(aggregated_data)
```

```{r}
write.csv(imputed, "data_3_imputed_kalman.csv")
```


# Normalization

```{r}
data_normal <- imputed %>%
  mutate_at(vars(arousal:appCat.weather), scale)
```







# Sleep


```{r}
# data <- combined_data
```


```{r}
# 21 - 12
data <- data %>% filter(beepo2 == 5 | beepo2 == 1)
```


## Observation Day
```{r}
# Adding a days_since_start column
data <- data %>% mutate(
  days_since_start = as.numeric(
    difftime(date, min(date), units = "days")))

# Check
unique(data$days_since_start)
```

```{r}
# Sort data by date_time
data <- data %>% arrange(ID, date_time)
```

```{r}
# Potential Hours 
data <- data %>% mutate(
  after_midnight_activity = (hour >= 0 & hour <= 6),
  # Wake up Hour (first observation after the difference)
  potential_sleep_hour = (hour >= 20 | hour <= 11),
  # Wake up Hour (first observation after the difference)
  potential_wakeup_hour = (hour >= 5 & hour <= 12))
```

## Potential Sleep Gap
```{r}
# Column for the time difference between 
# the current observation and the last observation
data <- data %>% group_by(ID) %>% mutate(
  # For every observation, getting the difference between the previous
  time_diff = round(
    difftime(date_time, lag(date_time),
             units = "hours"), 3),
  # Gap based on both these variables
  possible_sleep_gap = (time_diff >= 5 & time_diff <= 15) & 
    (potential_wakeup_hour == TRUE)) %>% 
  ungroup()
```

## Inactivity
```{r}
# Inactivity
data <- data %>% mutate(
  is_inactive = dplyr::case_when(
    is.na(activity) ~ FALSE,
    activity == 0 ~ TRUE,
    TRUE ~ FALSE))

# Applying a run-length encoding to count consecutive inactive periods
data <- data %>% group_by(ID) %>% mutate(
    consecutive_inactive = with(rle(is_inactive), {
      # Only count lengths where is_inactive is TRUE:
      lengths_corrected <- lengths * values  
      # Repeat these lengths according to run lengths:
      rep(lengths_corrected, lengths)   
    })) %>% 
  ungroup()
```

## Fragmented Sleep
```{r}
########  1  #############
# last inactive hour
data <- data %>%
  mutate(
    # Check if current observation is inactive
    last_inactive_hour = if_else(is_inactive, hour, 
                                            NA_integer_)
  ) %>%
  group_by(ID) %>%
  # Fill NA values with the last known inactive hour, carrying it forward
  fill(last_inactive_hour, .direction = "down") %>%
  ungroup()

########  2  ##########
# Assuming data is already loaded and date_time is in POSIXct format
data <- data %>%
  mutate(
    # Record the datetime of the last inactive observation
    last_inactive_time = if_else(is_inactive, date_time, as.POSIXct(NA))
  ) %>%
  group_by(ID) %>%
  # Fill NA values with the last known inactive datetime, carrying it forward
  fill(last_inactive_time, .direction = "down") %>%
  ungroup() %>%
  mutate(
    # Calculate the time difference in hours between now and the last inactive time
    time_since_last_inactive = if_else(is.na(last_inactive_time),
                                       NA_real_,
                                       as.numeric(difftime(date_time, last_inactive_time, units = "hours")))
  )
```


## WORKING ON IT NOW
```{r}
# Determine if sleep occurred after midnight
data <- data %>% mutate(
    slept_after_midnight = hour(date_time) >= 0 & hour(date_time) <= 6 & sleep == 1)

```




## Sleep
```{r}
data <- data %>% group_by(ID)%>% mutate(
  sleep = case_when(
    consecutive_inactive >= 4 & 
      potential_sleep_hour ~ consecutive_inactive, 
    
    possible_sleep_gap & 
      potential_wakeup_hour ~ round(as.numeric(time_diff)),
    
    TRUE ~ 0
  )
) %>% ungroup()
```










# Aggregating

```{r}
# aggregating the data by date, for all participants
aggregated_data <- data %>%
  group_by(date, ID) %>%
  summarise(
    mood = mean(mood, na.rm = TRUE),
    arousal = mean(circumplex.arousal, na.rm = TRUE),
    valence = mean(circumplex.valence, na.rm = TRUE),
    activity = mean(activity, na.rm = TRUE),
    # screen???
    call = sum(call, na.rm = TRUE),
    sms = sum(sms, na.rm = TRUE),
    appCat.builtin = sum(appCat.builtin, na.rm = TRUE),
    appCat.communication = sum(appCat.communication, na.rm = TRUE),
    appCat.entertainment = sum(appCat.entertainment, na.rm = TRUE),
    appCat.finance = sum(appCat.finance, na.rm = TRUE),
    appCat.game = sum(appCat.game, na.rm = TRUE),
    appCat.office = sum(appCat.office, na.rm = TRUE),
    appCat.other = sum(appCat.other, na.rm = TRUE),
    appCat.social = sum(appCat.social, na.rm = TRUE),
    appCat.travel = sum(appCat.travel, na.rm = TRUE),
    appCat.unknown = sum(appCat.unknown, na.rm = TRUE),
    appCat.utilities = sum(appCat.utilities, na.rm = TRUE), 
    appCat.weather = sum(appCat.weather, na.rm = TRUE), 
    .groups = "drop")

# Standardizing
aggregated_data_2 <- aggregated_data %>%
  mutate_at(vars(arousal:appCat.weather), scale)
colnames(aggregated_data_2)

# Model
model <- lme4::lmer(
  mood ~ arousal + 
    valence + 
    activity + 
    call + 
    sms + 
    appCat.builtin + 
    appCat.communication + 
    appCat.entertainment + 
    appCat.finance + 
    appCat.game + 
    appCat.office + 
    appCat.other + 
    appCat.social + 
    appCat.travel + 
    appCat.unknown + 
    appCat.utilities + 
    appCat.weather + 
    (1 + time|ID), 
  data = aggregated_data)
summary(model)


```


```{r}
write.csv(aggregated_data, "data_aggregated.csv")
```




# Network Shit

```{r}
load("ml_mod.RData")
```

```{r}
variables_network <- c("mood", "arousal", "valence", "activity", "call", "sms", "appCat.builtin", "appCat.communication", "appCat.entertainment", "appCat.finance", "appCat.game", "appCat.office", "appCat.other", "appCat.social",)
beep_new$
data_normal <- read.csv("data_for_analysis.csv")

variables_network <- c("mood", "arousal", "valence", "activity", "appCat.social")
# "call", "sms", "appCat.communication", "appCat.entertainment", "appCat.finance", "appCat.game", 

# multilevel vector autoregressive (mlVAR) model, 
# also regarded as a special case of the dynamic structural equation model (DSEM)
library(mlVAR)
ml_mod <- mlVAR::mlVAR(
  data_normal, 
  vars = variables_network, 
  idvar = "ID", 
  dayvar = "date", 
  estimator = "lmer", 
  beepvar = "beepo", 
  temporal = "correlated", 
  contemporaneous = "correlated")
```


```{r}
temp <- plot(ml_mod, 
             "temporal", 
             title="Temporal Network",
             layout = "circle", nonsig = "hide")

plot(ml_mod, "contemporaneous", title="Contemporaneous Network", rule = "and")

plot(ml_mod, "between", title="Between-Subject Network", rule = "and")

summary(ml_mod)
```



```{r}
# Assume ml_mod is already fitted
temp <- plot(ml_mod, 
             plotType = "temporal", 
             title = "Temporal Network",
             layout = layout_in_circle)  # Using igraph's layout

# Enhance plot aesthetics using igraph's options
plot.igraph(temp,
            main = "Temporal Network",
            vertex.label.color = "darkblue",
            vertex.label.cex = 0.8,  # Control label size
            vertex.size = 20,
            edge.arrow.size = 0.5,
            layout = layout_in_circle(temp))

temp <- mlVAR::plot(ml_mod, 
                    plotType = "temporal", 
                    title = "Temporal Network",
                    layout = "circle",
                    labels = TRUE,      # Ensure labels are shown if needed
                    edge.color = "black",
                    edge.width = 2,
                    vsize = 5,
                    color = "skyblue")


qgraph::qgraph(adj_matrix,
       layout = "circle",
       labels = colnames(adj_matrix),  # Ensure you have column names for labels
       title = "Temporal Network",
       edge.color = "black",
       edge.width = 2,
       vsize = 5,
       color = "skyblue") 
```







# Bayes stuff

```{r}
# mHMMbayes::

model <- mHMMbayes::mHMM(
  y = list(mood = aggregated_data$mood), # Add other response variables as needed
  id = aggregated_data$ID, 
  data = aggregated_data, 
  n_states = 3, # Example: 3 hidden states
  covars = list("trans" = ~ arousal + valence) # Example covariates for transitions
)
?mHMMbayes::mHMM
# Initial values (hypothetical)
start_values <- list(
  startProbs = rep(1/3, 3),
  transProbs = matrix(c(.8, .1, .1, .1, .8, .1, .1, .1, .8), nrow = 3),
  emissionProbs = list(mood = rep(1/3, 3))
)

# Fit the model
fitted_model <- fit_model(model, start_values = start_values, iter = 10000, burnin = 1000)

# Check results
summary(fitted_model)
```


# Clustering
```{r}
data <- data %>% mutate(
  mood_cat = )
```








